Index: jellyfin-ffmpeg/libavcodec/qsv.c
===================================================================
--- libavcodec/qsv.c
+++ libavcodec/qsv.c
@@ -608,7 +608,7 @@ static mfxStatus qsv_frame_alloc(mfxHDL
         AVHWFramesContext *frames_ctx = (AVHWFramesContext*)ctx->hw_frames_ctx->data;
         AVQSVFramesContext *frames_hwctx = frames_ctx->hwctx;
         mfxFrameInfo      *i  = &req->Info;
-        mfxFrameInfo      *i1 = &frames_hwctx->surfaces[0].Info;
+        mfxFrameInfo      *i1 = &frames_hwctx->reserve_surface.Info;
 
         if (i->Width  > i1->Width  || i->Height > i1->Height ||
             i->FourCC != i1->FourCC || i->ChromaFormat != i1->ChromaFormat) {
@@ -723,7 +723,7 @@ static mfxStatus qsv_frame_lock(mfxHDL p
     if (!qsv_mid->hw_frame->hw_frames_ctx)
         goto fail;
 
-    qsv_mid->surf.Info = hw_frames_hwctx->surfaces[0].Info;
+    qsv_mid->surf.Info = hw_frames_hwctx->reserve_surface.Info;
     qsv_mid->surf.Data.MemId = qsv_mid->handle_pair;
 
     /* map the data to the system memory */
Index: jellyfin-ffmpeg/libavcodec/qsvenc.c
===================================================================
--- libavcodec/qsvenc.c
+++ libavcodec/qsvenc.c
@@ -572,8 +572,8 @@ static int init_video_param_jpeg(AVCodec
     if (avctx->hw_frames_ctx) {
         AVHWFramesContext *frames_ctx    = (AVHWFramesContext *)avctx->hw_frames_ctx->data;
         AVQSVFramesContext *frames_hwctx = frames_ctx->hwctx;
-        q->param.mfx.FrameInfo.Width  = frames_hwctx->surfaces[0].Info.Width;
-        q->param.mfx.FrameInfo.Height = frames_hwctx->surfaces[0].Info.Height;
+        q->param.mfx.FrameInfo.Width  = frames_hwctx->reserve_surface.Info.Width;
+        q->param.mfx.FrameInfo.Height = frames_hwctx->reserve_surface.Info.Height;
     }
 
     if (avctx->framerate.den > 0 && avctx->framerate.num > 0) {
@@ -690,8 +690,8 @@ static int init_video_param(AVCodecConte
     if (avctx->hw_frames_ctx) {
         AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;
         AVQSVFramesContext *frames_hwctx = frames_ctx->hwctx;
-        q->param.mfx.FrameInfo.Width  = frames_hwctx->surfaces[0].Info.Width;
-        q->param.mfx.FrameInfo.Height = frames_hwctx->surfaces[0].Info.Height;
+        q->param.mfx.FrameInfo.Width  = frames_hwctx->reserve_surface.Info.Width;
+        q->param.mfx.FrameInfo.Height = frames_hwctx->reserve_surface.Info.Height;
     }
 
     if (avctx->framerate.den > 0 && avctx->framerate.num > 0) {
Index: jellyfin-ffmpeg/libavcodec/qsvenc_hevc.c
===================================================================
--- libavcodec/qsvenc_hevc.c
+++ libavcodec/qsvenc_hevc.c
@@ -287,9 +287,9 @@ static const AVClass class = {
 static const FFCodecDefault qsv_enc_defaults[] = {
     { "b",         "1M"    },
     { "refs",      "0"     },
-    // same as the x264 default
+    // same as the x265 default
     { "g",         "248"   },
-    { "bf",        "-1"    },
+    { "bf",        "4"     },
     { "qmin",      "-1"    },
     { "qmax",      "-1"    },
     { "trellis",   "-1"    },
Index: jellyfin-ffmpeg/libavfilter/qsvvpp.c
===================================================================
--- libavfilter/qsvvpp.c
+++ libavfilter/qsvvpp.c
@@ -274,7 +274,7 @@ static int fill_frameinfo_by_link(mfxFra
 
         frames_ctx   = (AVHWFramesContext *)link->hw_frames_ctx->data;
         frames_hwctx = frames_ctx->hwctx;
-        *frameinfo   = frames_hwctx->surfaces[0].Info;
+        *frameinfo   = frames_hwctx->reserve_surface.Info;
     } else {
         pix_fmt = link->format;
         desc = av_pix_fmt_desc_get(pix_fmt);
Index: jellyfin-ffmpeg/libavutil/hwcontext_qsv.c
===================================================================
--- libavutil/hwcontext_qsv.c
+++ libavutil/hwcontext_qsv.c
@@ -569,7 +569,7 @@ static mfxStatus frame_alloc(mfxHDL pthi
     QSVFramesContext       *s = ctx->internal->priv;
     AVQSVFramesContext *hwctx = ctx->hwctx;
     mfxFrameInfo *i  = &req->Info;
-    mfxFrameInfo *i1 = &hwctx->surfaces[0].Info;
+    mfxFrameInfo *i1 = &hwctx->reserve_surface.Info;
 
     if (!(req->Type & MFX_MEMTYPE_VIDEO_MEMORY_PROCESSOR_TARGET) ||
         !(req->Type & (MFX_MEMTYPE_FROM_VPPIN | MFX_MEMTYPE_FROM_VPPOUT)) ||
@@ -672,7 +672,7 @@ static int qsv_init_internal_session(AVH
                               MFX_IOPATTERN_OUT_SYSTEM_MEMORY;
     par.AsyncDepth = 1;
 
-    par.vpp.In = frames_hwctx->surfaces[0].Info;
+    par.vpp.In = frames_hwctx->reserve_surface.Info;
 
     /* Apparently VPP requires the frame rate to be set to some value, otherwise
      * init will fail (probably for the framerate conversion filter). Since we
@@ -745,6 +745,12 @@ static int qsv_frames_init(AVHWFramesCon
             s->mem_ids[i] = frames_hwctx->surfaces[i].Data.MemId;
     }
 
+    ret = qsv_init_surface(ctx, &frames_hwctx->reserve_surface);
+    if (ret < 0) {
+        av_freep(&s->surface_ptrs);
+        return ret;
+    }
+
     s->session_download = NULL;
     s->session_upload   = NULL;
 
@@ -1264,13 +1270,7 @@ static int qsv_frames_derive_to(AVHWFram
 {
     QSVFramesContext *s = dst_ctx->internal->priv;
     AVQSVFramesContext *dst_hwctx = dst_ctx->hwctx;
-    int i;
-
-    if (src_ctx->initial_pool_size == 0) {
-        av_log(dst_ctx, AV_LOG_ERROR, "Only fixed-size pools can be "
-            "mapped to QSV frames.\n");
-        return AVERROR(EINVAL);
-    }
+    int i, ret;
 
     switch (src_ctx->device_ctx->type) {
 #if CONFIG_VAAPI
@@ -1286,11 +1286,20 @@ static int qsv_frames_derive_to(AVHWFram
             if (!s->surfaces_internal)
                 return AVERROR(ENOMEM);
             for (i = 0; i < src_hwctx->nb_surfaces; i++) {
-                qsv_init_surface(dst_ctx, &s->surfaces_internal[i]);
+                ret = qsv_init_surface(dst_ctx, &s->surfaces_internal[i]);
+                if (ret < 0) {
+                    av_freep(&s->surfaces_internal);
+                    return ret;
+                }
                 s->handle_pairs_internal[i].first = src_hwctx->surface_ids + i;
                 s->handle_pairs_internal[i].second = (mfxMemId)MFX_INFINITE;
                 s->surfaces_internal[i].Data.MemId = (mfxMemId)&s->handle_pairs_internal[i];
             }
+            ret = qsv_init_surface(dst_ctx, &dst_hwctx->reserve_surface);
+            if (ret < 0) {
+                av_freep(&s->surfaces_internal);
+                return ret;
+            }
             dst_hwctx->nb_surfaces = src_hwctx->nb_surfaces;
             dst_hwctx->frame_type  = MFX_MEMTYPE_VIDEO_MEMORY_DECODER_TARGET;
         }
@@ -1309,7 +1318,11 @@ static int qsv_frames_derive_to(AVHWFram
             if (!s->surfaces_internal)
                 return AVERROR(ENOMEM);
             for (i = 0; i < src_ctx->initial_pool_size; i++) {
-                qsv_init_surface(dst_ctx, &s->surfaces_internal[i]);
+                ret = qsv_init_surface(dst_ctx, &s->surfaces_internal[i]);
+                if (ret < 0) {
+                    av_freep(&s->surfaces_internal);
+                    return ret;
+                }
                 s->handle_pairs_internal[i].first = (mfxMemId)src_hwctx->texture_infos[i].texture;
                 if (src_hwctx->BindFlags & D3D11_BIND_RENDER_TARGET) {
                     s->handle_pairs_internal[i].second = (mfxMemId)MFX_INFINITE;
@@ -1318,6 +1331,11 @@ static int qsv_frames_derive_to(AVHWFram
                 }
                 s->surfaces_internal[i].Data.MemId = (mfxMemId)&s->handle_pairs_internal[i];
             }
+            ret = qsv_init_surface(dst_ctx, &dst_hwctx->reserve_surface);
+            if (ret < 0) {
+                av_freep(&s->surfaces_internal);
+                return ret;
+            }
             dst_hwctx->nb_surfaces = src_ctx->initial_pool_size;
             if (src_hwctx->BindFlags & D3D11_BIND_RENDER_TARGET) {
                 dst_hwctx->frame_type |= MFX_MEMTYPE_VIDEO_MEMORY_PROCESSOR_TARGET;
@@ -1340,11 +1358,20 @@ static int qsv_frames_derive_to(AVHWFram
             if (!s->surfaces_internal)
                 return AVERROR(ENOMEM);
             for (i = 0; i < src_hwctx->nb_surfaces; i++) {
-                qsv_init_surface(dst_ctx, &s->surfaces_internal[i]);
+                ret = qsv_init_surface(dst_ctx, &s->surfaces_internal[i]);
+                if (ret < 0) {
+                    av_freep(&s->surfaces_internal);
+                    return ret;
+                }
                 s->handle_pairs_internal[i].first = (mfxMemId)src_hwctx->surfaces[i];
                 s->handle_pairs_internal[i].second = (mfxMemId)MFX_INFINITE;
                 s->surfaces_internal[i].Data.MemId = (mfxMemId)&s->handle_pairs_internal[i];
             }
+            ret = qsv_init_surface(dst_ctx, &dst_hwctx->reserve_surface);
+            if (ret < 0) {
+                av_freep(&s->surfaces_internal);
+                return ret;
+            }
             dst_hwctx->nb_surfaces = src_hwctx->nb_surfaces;
             if (src_hwctx->surface_type == DXVA2_VideoProcessorRenderTarget)
                 dst_hwctx->frame_type = MFX_MEMTYPE_VIDEO_MEMORY_PROCESSOR_TARGET;
Index: jellyfin-ffmpeg/libavutil/hwcontext_qsv.h
===================================================================
--- libavutil/hwcontext_qsv.h
+++ libavutil/hwcontext_qsv.h
@@ -43,6 +43,12 @@ typedef struct AVQSVFramesContext {
     mfxFrameSurface1 *surfaces;
     int            nb_surfaces;
 
+    /*
+     * This surface store the surface information,
+     * and can be used to init dec, enc and vpp.
+     */
+    mfxFrameSurface1 reserve_surface;
+
     /**
      * A combination of MFX_MEMTYPE_* describing the frame pool.
      */
