Index: jellyfin-ffmpeg/configure
===================================================================
--- configure
+++ configure
@@ -3601,6 +3601,7 @@ openclsrc_filter_deps="opencl"
 overlay_opencl_filter_deps="opencl"
 overlay_qsv_filter_deps="libmfx"
 overlay_qsv_filter_select="qsvvpp"
+overlay_vaapi_filter_deps="vaapi"
 overlay_vulkan_filter_deps="vulkan libglslang"
 owdenoise_filter_deps="gpl"
 pad_opencl_filter_deps="opencl"
@@ -3662,6 +3663,7 @@ tonemap_vaapi_filter_deps="vaapi VAProcF
 tonemap_opencl_filter_deps="opencl const_nan"
 transpose_opencl_filter_deps="opencl"
 transpose_vaapi_filter_deps="vaapi VAProcPipelineCaps_rotation_flags"
+overlay_vaapi_filter_deps="vaapi VAProcPipelineCaps_blend_flags"
 unsharp_opencl_filter_deps="opencl"
 uspp_filter_deps="gpl avcodec"
 vaguedenoiser_filter_deps="gpl"
@@ -6712,6 +6714,7 @@ if enabled vaapi; then
     check_struct "va/va.h" "VADecPictureParameterBufferAV1" bit_depth_idx
     check_type   "va/va.h va/va_vpp.h" "VAProcFilterParameterBufferHDRToneMapping"
     check_struct "va/va.h va/va_vpp.h" "VAProcPipelineCaps" rotation_flags
+    check_struct "va/va.h va/va_vpp.h" "VAProcPipelineCaps" blend_flags
     check_type "va/va.h va/va_enc_hevc.h" "VAEncPictureParameterBufferHEVC"
     check_type "va/va.h va/va_enc_jpeg.h" "VAEncPictureParameterBufferJPEG"
     check_type "va/va.h va/va_enc_vp8.h"  "VAEncPictureParameterBufferVP8"
Index: jellyfin-ffmpeg/libavfilter/Makefile
===================================================================
--- libavfilter/Makefile
+++ libavfilter/Makefile
@@ -353,6 +353,7 @@ OBJS-$(CONFIG_OVERLAY_CUDA_FILTER)
 OBJS-$(CONFIG_OVERLAY_OPENCL_FILTER)         += vf_overlay_opencl.o opencl.o \
                                                 opencl/overlay.o framesync.o
 OBJS-$(CONFIG_OVERLAY_QSV_FILTER)            += vf_overlay_qsv.o framesync.o
+OBJS-$(CONFIG_OVERLAY_VAAPI_FILTER)          += vf_overlay_vaapi.o framesync.o vaapi_vpp.o
 OBJS-$(CONFIG_OVERLAY_VULKAN_FILTER)         += vf_overlay_vulkan.o vulkan.o
 OBJS-$(CONFIG_OWDENOISE_FILTER)              += vf_owdenoise.o
 OBJS-$(CONFIG_PAD_FILTER)                    += vf_pad.o
Index: jellyfin-ffmpeg/libavfilter/allfilters.c
===================================================================
--- libavfilter/allfilters.c
+++ libavfilter/allfilters.c
@@ -336,6 +336,7 @@ extern AVFilter ff_vf_oscilloscope;
 extern AVFilter ff_vf_overlay;
 extern AVFilter ff_vf_overlay_opencl;
 extern AVFilter ff_vf_overlay_qsv;
+extern AVFilter ff_vf_overlay_vaapi;
 extern AVFilter ff_vf_overlay_vulkan;
 extern AVFilter ff_vf_overlay_cuda;
 extern AVFilter ff_vf_owdenoise;
Index: jellyfin-ffmpeg/libavfilter/vf_overlay_vaapi.c
===================================================================
--- /dev/null
+++ libavfilter/vf_overlay_vaapi.c
@@ -0,0 +1,468 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+#include <string.h>
+
+#include "libavutil/avassert.h"
+#include "libavutil/mem.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+
+#include "avfilter.h"
+#include "framesync.h"
+#include "formats.h"
+#include "internal.h"
+#include "vaapi_vpp.h"
+
+typedef struct OverlayVAAPIContext {
+    VAAPIVPPContext  vpp_ctx; // must be the first field
+    FFFrameSync      fs;
+    int              global_alpha_flag;
+    int              premultiplied_alpha_flag;
+    int              pixel_alpha_enabled;
+    int              overlay_ox;
+    int              overlay_oy;
+    int              overlay_ow;
+    int              overlay_oh;
+    float            alpha;
+    int              opt_repeatlast;
+    int              opt_shortest;
+    int              opt_eof_action;
+} OverlayVAAPIContext;
+
+static int overlay_vaapi_query_formats(AVFilterContext *ctx)
+{
+    int ret;
+    enum {
+        MAIN    = 0,
+        OVERLAY = 1,
+    };
+
+    static const enum AVPixelFormat pix_fmts[] = {
+        AV_PIX_FMT_VAAPI,
+        AV_PIX_FMT_NONE
+    };
+
+    ret = ff_formats_ref(ff_make_format_list(pix_fmts), &ctx->inputs[MAIN]->outcfg.formats);
+    if (ret < 0)
+        return ret;
+
+    ret = ff_formats_ref(ff_make_format_list(pix_fmts), &ctx->inputs[OVERLAY]->outcfg.formats);
+    if (ret < 0)
+        return ret;
+
+    ret = ff_formats_ref(ff_make_format_list(pix_fmts), &ctx->outputs[0]->incfg.formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int overlay_vaapi_build_filter_params(AVFilterContext *avctx)
+{
+    VAAPIVPPContext *vpp_ctx = avctx->priv;
+    OverlayVAAPIContext *ctx = avctx->priv;
+    VAProcPipelineCaps pipeline_caps;
+    VAStatus vas;
+
+    memset(&pipeline_caps, 0, sizeof(pipeline_caps));
+    vas = vaQueryVideoProcPipelineCaps(vpp_ctx->hwctx->display,
+                                       vpp_ctx->va_context,
+                                       NULL, 0,
+                                       &pipeline_caps);
+    if (vas != VA_STATUS_SUCCESS) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to query pipeline "
+               "caps: %d (%s).\n", vas, vaErrorStr(vas));
+        return AVERROR(EIO);
+    }
+
+    if (!pipeline_caps.blend_flags) {
+        av_log(avctx, AV_LOG_ERROR, "VAAPI driver doesn't support overlay\n");
+        return AVERROR(EINVAL);
+    }
+
+    ctx->global_alpha_flag = pipeline_caps.blend_flags & VA_BLEND_GLOBAL_ALPHA;
+    if (!ctx->global_alpha_flag) {
+        av_log(avctx, AV_LOG_ERROR, "VAAPI driver doesn't support global alpha blending\n");
+        return AVERROR(EINVAL);
+    }
+
+    ctx->premultiplied_alpha_flag = pipeline_caps.blend_flags & VA_BLEND_PREMULTIPLIED_ALPHA;
+    if (!ctx->premultiplied_alpha_flag) {
+        av_log(avctx, AV_LOG_WARNING, "VAAPI driver doesn't support premultiplied alpha blending, "
+               "alpha planar of the overlay frames will be ignored\n");
+    }
+
+    return 0;
+}
+
+
+static int overlay_vaapi_render_picture(AVFilterContext *avctx,
+                                        VAProcPipelineParameterBuffer *params,
+                                        VAProcPipelineParameterBuffer *subpic_params,
+                                        AVFrame *output_frame,
+                                        int passthrough)
+{
+    VAAPIVPPContext *ctx   = avctx->priv;
+    VASurfaceID output_surface;
+    VABufferID params_id;
+    VABufferID subpic_params_id;
+    VAStatus vas;
+    int err = 0;
+
+    output_surface = (VASurfaceID)(uintptr_t)output_frame->data[3];
+
+    vas = vaBeginPicture(ctx->hwctx->display,
+                         ctx->va_context, output_surface);
+    if (vas != VA_STATUS_SUCCESS) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to attach new picture: "
+               "%d (%s).\n", vas, vaErrorStr(vas));
+        err = AVERROR(EIO);
+        goto fail;
+    }
+
+    vas = vaCreateBuffer(ctx->hwctx->display, ctx->va_context,
+                         VAProcPipelineParameterBufferType,
+                         sizeof(*params), 1, params, &params_id);
+    if (vas != VA_STATUS_SUCCESS) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to create parameter buffer: "
+               "%d (%s).\n", vas, vaErrorStr(vas));
+        err = AVERROR(EIO);
+        goto fail_after_begin;
+    }
+    av_log(avctx, AV_LOG_DEBUG, "Pipeline parameter buffer is %#x.\n",
+           params_id);
+
+    if (!passthrough) {
+        vas = vaCreateBuffer(ctx->hwctx->display, ctx->va_context,
+                             VAProcPipelineParameterBufferType,
+                             sizeof(*subpic_params), 1, subpic_params, &subpic_params_id);
+        if (vas != VA_STATUS_SUCCESS) {
+            av_log(avctx, AV_LOG_ERROR, "Failed to create parameter buffer: "
+                   "%d (%s).\n", vas, vaErrorStr(vas));
+            err = AVERROR(EIO);
+            goto fail_after_begin;
+        }
+        av_log(avctx, AV_LOG_DEBUG, "Pipeline subpic parameter buffer is %#x.\n",
+               subpic_params_id);
+    }
+
+    vas = vaRenderPicture(ctx->hwctx->display, ctx->va_context,
+                          &params_id, 1);
+    if (vas != VA_STATUS_SUCCESS) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to render parameter buffer: "
+               "%d (%s).\n", vas, vaErrorStr(vas));
+        err = AVERROR(EIO);
+        goto fail_after_begin;
+    }
+
+    if (!passthrough) {
+        vas = vaRenderPicture(ctx->hwctx->display, ctx->va_context,
+                              &subpic_params_id, 1);
+        if (vas != VA_STATUS_SUCCESS) {
+            av_log(avctx, AV_LOG_ERROR, "Failed to render subpic parameter buffer: "
+                   "%d (%s).\n", vas, vaErrorStr(vas));
+            err = AVERROR(EIO);
+            goto fail_after_begin;
+        }
+    }
+
+    vas = vaEndPicture(ctx->hwctx->display, ctx->va_context);
+    if (vas != VA_STATUS_SUCCESS) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to start picture processing: "
+               "%d (%s).\n", vas, vaErrorStr(vas));
+        err = AVERROR(EIO);
+        goto fail_after_render;
+    }
+
+    if (CONFIG_VAAPI_1 || ctx->hwctx->driver_quirks &
+        AV_VAAPI_DRIVER_QUIRK_RENDER_PARAM_BUFFERS) {
+        vas = vaDestroyBuffer(ctx->hwctx->display, params_id);
+        if (vas != VA_STATUS_SUCCESS) {
+            av_log(avctx, AV_LOG_ERROR, "Failed to free parameter buffer: "
+                   "%d (%s).\n", vas, vaErrorStr(vas));
+            // And ignore.
+        }
+    }
+
+    return 0;
+
+    // We want to make sure that if vaBeginPicture has been called, we also
+    // call vaRenderPicture and vaEndPicture.  These calls may well fail or
+    // do something else nasty, but once we're in this failure case there
+    // isn't much else we can do.
+fail_after_begin:
+    vaRenderPicture(ctx->hwctx->display, ctx->va_context, &params_id, 1);
+fail_after_render:
+    vaEndPicture(ctx->hwctx->display, ctx->va_context);
+fail:
+    return err;
+}
+
+static int overlay_vaapi_blend(FFFrameSync *fs)
+{
+    AVFilterContext    *avctx = fs->parent;
+    AVFilterLink     *outlink = avctx->outputs[0];
+    OverlayVAAPIContext *ctx  = avctx->priv;
+    VAAPIVPPContext *vpp_ctx  = avctx->priv;
+    AVFrame *input_main, *input_overlay;
+    AVFrame *output;
+    VAProcPipelineParameterBuffer params, subpic_params;
+    VABlendState blend_state;
+    VARectangle overlay_region, output_region;
+    int err, passthrough = 0;
+
+    err = ff_framesync_get_frame(fs, 0, &input_main, 0);
+    if (err < 0)
+        return err;
+    err = ff_framesync_get_frame(fs, 1, &input_overlay, 0);
+    if (err < 0)
+        return err;
+
+    if (!input_main)
+        return AVERROR_BUG;
+
+    if (!input_overlay)
+        passthrough = 1;
+
+    av_log(avctx, AV_LOG_DEBUG, "Filter main: %s, %ux%u (%"PRId64").\n",
+           av_get_pix_fmt_name(input_main->format),
+           input_main->width, input_main->height, input_main->pts);
+
+    if (input_overlay) {
+        av_log(avctx, AV_LOG_DEBUG, "Filter overlay: %s, %ux%u (%"PRId64").\n",
+               av_get_pix_fmt_name(input_overlay->format),
+               input_overlay->width, input_overlay->height, input_overlay->pts);
+    }
+
+    if (vpp_ctx->va_context == VA_INVALID_ID)
+        return AVERROR(EINVAL);
+
+    output = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!output) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    err = av_frame_copy_props(output, input_main);
+    if (err < 0)
+        goto fail;
+
+    err = ff_vaapi_vpp_init_params(avctx, &params,
+                                   input_main, output);
+    if (err < 0)
+        goto fail;
+
+    output_region = (VARectangle) {
+        .x      = 0,
+        .y      = 0,
+        .width  = output->width,
+        .height = output->height,
+    };
+
+    params.filters     = &vpp_ctx->filter_buffers[0];
+    params.num_filters = vpp_ctx->nb_filter_buffers;
+
+    params.output_region = &output_region;
+    params.output_background_color = VAAPI_VPP_BACKGROUND_BLACK;
+
+    if (!passthrough) {
+        overlay_region = (VARectangle) {
+            .x      = ctx->overlay_ox,
+            .y      = ctx->overlay_oy,
+            .width  = ctx->overlay_ow ? ctx->overlay_ow : input_overlay->width,
+            .height = ctx->overlay_oh ? ctx->overlay_oh : input_overlay->height,
+        };
+
+        if (overlay_region.x + overlay_region.width > input_main->width ||
+            overlay_region.y + overlay_region.height > input_main->height) {
+            av_log(ctx, AV_LOG_WARNING,
+                   "The overlay image exceeds the scope of the main image, "
+                   "will crop the overlay image according based on the main image.\n");
+        }
+
+        memcpy(&subpic_params, &params, sizeof(subpic_params));
+
+        blend_state.flags = VA_BLEND_GLOBAL_ALPHA;
+        if (ctx->pixel_alpha_enabled)
+            blend_state.flags |= VA_BLEND_PREMULTIPLIED_ALPHA;
+
+        blend_state.global_alpha = ctx->alpha;
+        subpic_params.blend_state = &blend_state;
+
+        subpic_params.surface = (VASurfaceID)(uintptr_t)input_overlay->data[3];
+        subpic_params.output_region = &overlay_region;
+    }
+
+    err = overlay_vaapi_render_picture(avctx, &params, &subpic_params, output, passthrough);
+    if (err < 0)
+        goto fail;
+
+    av_log(avctx, AV_LOG_DEBUG, "Filter output: %s, %ux%u (%"PRId64").\n",
+           av_get_pix_fmt_name(output->format),
+           output->width, output->height, output->pts);
+
+    return ff_filter_frame(outlink, output);
+
+fail:
+    av_frame_free(&output);
+    return err;
+}
+
+static int overlay_vaapi_init_framesync(AVFilterContext *avctx)
+{
+    OverlayVAAPIContext *ctx = avctx->priv;
+    AVFilterLink    *outlink = avctx->outputs[0];
+    int ret;
+
+    ret = ff_framesync_init_dualinput(&ctx->fs, avctx);
+    if (ret < 0)
+        return ret;
+
+    ctx->fs.opt_repeatlast = ctx->opt_repeatlast;
+    ctx->fs.opt_shortest   = ctx->opt_shortest;
+    ctx->fs.opt_eof_action = ctx->opt_eof_action;
+    ctx->fs.time_base      = outlink->time_base;
+    ctx->fs.on_event       = overlay_vaapi_blend;
+    ctx->fs.opaque         = ctx;
+
+    return ff_framesync_configure(&ctx->fs);
+}
+
+static int overlay_vaapi_config_output(AVFilterLink *outlink)
+{
+    AVFilterContext   *avctx = outlink->src;
+    OverlayVAAPIContext *ctx = avctx->priv;
+    VAAPIVPPContext *vpp_ctx = avctx->priv;
+    AVFilterLink    *inlink0 = avctx->inputs[0];
+    AVFilterLink    *inlink1 = avctx->inputs[1];
+    AVHWFramesContext *frames_ctx1 =
+        (AVHWFramesContext*)inlink1->hw_frames_ctx->data;
+    const AVPixFmtDescriptor *desc;
+    int err;
+
+    outlink->time_base     = inlink0->time_base;
+    vpp_ctx->output_width  = inlink0->w;
+    vpp_ctx->output_height = inlink0->h;
+
+    err = overlay_vaapi_init_framesync(avctx);
+    if (err < 0)
+        return err;
+
+    err = ff_vaapi_vpp_config_output(outlink);
+    if (err < 0)
+        return err;
+
+    desc = av_pix_fmt_desc_get(frames_ctx1->sw_format);
+    if (!desc)
+        return AVERROR(EINVAL);
+
+    ctx->pixel_alpha_enabled = (desc->flags & AV_PIX_FMT_FLAG_ALPHA)
+        && ctx->premultiplied_alpha_flag;
+
+    return 0;
+}
+
+static av_cold int overlay_vaapi_init(AVFilterContext *avctx)
+{
+    VAAPIVPPContext *vpp_ctx = avctx->priv;
+
+    ff_vaapi_vpp_ctx_init(avctx);
+    vpp_ctx->build_filter_params = overlay_vaapi_build_filter_params;
+    vpp_ctx->pipeline_uninit = ff_vaapi_vpp_pipeline_uninit;
+    vpp_ctx->output_format = AV_PIX_FMT_NONE;
+
+    return 0;
+}
+
+static int overlay_vaapi_activate(AVFilterContext *avctx)
+{
+    OverlayVAAPIContext *ctx = avctx->priv;
+
+    return ff_framesync_activate(&ctx->fs);
+}
+
+static av_cold void overlay_vaapi_uninit(AVFilterContext *avctx)
+{
+    OverlayVAAPIContext *ctx = avctx->priv;
+
+    ff_framesync_uninit(&ctx->fs);
+}
+
+#define OFFSET(x) offsetof(OverlayVAAPIContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption overlay_vaapi_options[] = {
+    { "x", "Overlay x position",
+      OFFSET(overlay_ox), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS },
+    { "y", "Overlay y position",
+      OFFSET(overlay_oy), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS },
+    { "w", "Overlay width",
+      OFFSET(overlay_ow), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS },
+    { "h", "Overlay height",
+      OFFSET(overlay_oh), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS },
+    { "alpha", "Overlay global alpha",
+      OFFSET(alpha), AV_OPT_TYPE_FLOAT, { .dbl = 1.0 }, 0.0, 1.0, .flags = FLAGS },
+    { "eof_action", "Action to take when encountering EOF from secondary input ",
+        OFFSET(opt_eof_action), AV_OPT_TYPE_INT, { .i64 = EOF_ACTION_REPEAT },
+        EOF_ACTION_REPEAT, EOF_ACTION_PASS, .flags = FLAGS, "eof_action" },
+        { "repeat", "Repeat the previous frame.",   0, AV_OPT_TYPE_CONST, { .i64 = EOF_ACTION_REPEAT }, .flags = FLAGS, "eof_action" },
+        { "endall", "End both streams.",            0, AV_OPT_TYPE_CONST, { .i64 = EOF_ACTION_ENDALL }, .flags = FLAGS, "eof_action" },
+        { "pass",   "Pass through the main input.", 0, AV_OPT_TYPE_CONST, { .i64 = EOF_ACTION_PASS },   .flags = FLAGS, "eof_action" },
+    { "shortest", "force termination when the shortest input terminates", OFFSET(opt_shortest), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, FLAGS },
+    { "repeatlast", "repeat overlay of the last overlay frame", OFFSET(opt_repeatlast), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, FLAGS },
+    { NULL },
+};
+
+AVFILTER_DEFINE_CLASS(overlay_vaapi);
+
+static const AVFilterPad overlay_vaapi_inputs[] = {
+    {
+        .name             = "main",
+        .type             = AVMEDIA_TYPE_VIDEO,
+        .get_video_buffer = ff_default_get_video_buffer,
+        .config_props     = &ff_vaapi_vpp_config_input,
+    },
+    {
+        .name             = "overlay",
+        .type             = AVMEDIA_TYPE_VIDEO,
+        .get_video_buffer = ff_default_get_video_buffer,
+    },
+    { NULL }
+};
+
+static const AVFilterPad overlay_vaapi_outputs[] = {
+    {
+        .name          = "default",
+        .type          = AVMEDIA_TYPE_VIDEO,
+        .config_props  = &overlay_vaapi_config_output,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_overlay_vaapi = {
+    .name            = "overlay_vaapi",
+    .description     = NULL_IF_CONFIG_SMALL("Overlay one video on top of another"),
+    .priv_size       = sizeof(OverlayVAAPIContext),
+    .priv_class      = &overlay_vaapi_class,
+    .init            = &overlay_vaapi_init,
+    .uninit          = &overlay_vaapi_uninit,
+    .query_formats   = &overlay_vaapi_query_formats,
+    .activate        = &overlay_vaapi_activate,
+    .inputs          = overlay_vaapi_inputs,
+    .outputs         = overlay_vaapi_outputs,
+    .flags_internal  = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
