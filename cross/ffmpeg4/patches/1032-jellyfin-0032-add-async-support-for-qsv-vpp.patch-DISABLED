Index: jellyfin-ffmpeg/libavcodec/qsv.c
===================================================================
--- libavcodec/qsv.c
+++ libavcodec/qsv.c
@@ -191,7 +191,7 @@ int ff_qsv_print_warning(void *log_ctx,
     const char *desc;
     int ret;
     ret = ff_qsv_map_error(err, &desc);
-    av_log(log_ctx, AV_LOG_WARNING, "%s: %s (%d)\n", warning_string, desc, err);
+    av_log(log_ctx, AV_LOG_VERBOSE, "%s: %s (%d)\n", warning_string, desc, err);
     return ret;
 }
 
Index: jellyfin-ffmpeg/libavfilter/Makefile
===================================================================
--- libavfilter/Makefile
+++ libavfilter/Makefile
@@ -231,7 +231,7 @@ OBJS-$(CONFIG_DECONVOLVE_FILTER)
 OBJS-$(CONFIG_DEDOT_FILTER)                  += vf_dedot.o
 OBJS-$(CONFIG_DEFLATE_FILTER)                += vf_neighbor.o
 OBJS-$(CONFIG_DEFLICKER_FILTER)              += vf_deflicker.o
-OBJS-$(CONFIG_DEINTERLACE_QSV_FILTER)        += vf_deinterlace_qsv.o
+OBJS-$(CONFIG_DEINTERLACE_QSV_FILTER)        += vf_vpp_qsv.o
 OBJS-$(CONFIG_DEINTERLACE_VAAPI_FILTER)      += vf_deinterlace_vaapi.o vaapi_vpp.o
 OBJS-$(CONFIG_DEJUDDER_FILTER)               += vf_dejudder.o
 OBJS-$(CONFIG_DELOGO_FILTER)                 += vf_delogo.o
@@ -397,7 +397,7 @@ OBJS-$(CONFIG_SCALE_FILTER)
 OBJS-$(CONFIG_SCALE_CUDA_FILTER)             += vf_scale_cuda.o vf_scale_cuda.ptx.o scale_eval.o
 OBJS-$(CONFIG_SCALE_NPP_FILTER)              += vf_scale_npp.o scale_eval.o
 OBJS-$(CONFIG_SCALE_OPENCL_FILTER)           += vf_scale_opencl.o opencl.o opencl/scale.o scale_eval.o
-OBJS-$(CONFIG_SCALE_QSV_FILTER)              += vf_scale_qsv.o
+OBJS-$(CONFIG_SCALE_QSV_FILTER)              += vf_vpp_qsv.o
 OBJS-$(CONFIG_SCALE_VAAPI_FILTER)            += vf_scale_vaapi.o scale_eval.o vaapi_vpp.o
 OBJS-$(CONFIG_SCALE_VULKAN_FILTER)           += vf_scale_vulkan.o vulkan.o
 OBJS-$(CONFIG_SCALE2REF_FILTER)              += vf_scale.o scale_eval.o
Index: jellyfin-ffmpeg/libavfilter/qsvvpp.c
===================================================================
--- libavfilter/qsvvpp.c
+++ libavfilter/qsvvpp.c
@@ -36,38 +36,6 @@
                                         MFX_MEMTYPE_VIDEO_MEMORY_PROCESSOR_TARGET))
 #define IS_OPAQUE_MEMORY(mode) (mode & MFX_MEMTYPE_OPAQUE_FRAME)
 #define IS_SYSTEM_MEMORY(mode) (mode & MFX_MEMTYPE_SYSTEM_MEMORY)
-
-typedef struct QSVFrame {
-    AVFrame          *frame;
-    mfxFrameSurface1 *surface;
-    mfxFrameSurface1  surface_internal;  /* for system memory */
-    struct QSVFrame  *next;
-} QSVFrame;
-
-/* abstract struct for all QSV filters */
-struct QSVVPPContext {
-    mfxSession          session;
-    int (*filter_frame) (AVFilterLink *outlink, AVFrame *frame);/* callback */
-    enum AVPixelFormat  out_sw_format;   /* Real output format */
-    mfxVideoParam       vpp_param;
-    mfxFrameInfo       *frame_infos;     /* frame info for each input */
-
-    /* members related to the input/output surface */
-    int                 in_mem_mode;
-    int                 out_mem_mode;
-    QSVFrame           *in_frame_list;
-    QSVFrame           *out_frame_list;
-    int                 nb_surface_ptrs_in;
-    int                 nb_surface_ptrs_out;
-    mfxFrameSurface1  **surface_ptrs_in;
-    mfxFrameSurface1  **surface_ptrs_out;
-
-    /* MFXVPP extern parameters */
-    mfxExtOpaqueSurfaceAlloc opaque_alloc;
-    mfxExtBuffer      **ext_buffers;
-    int                 nb_ext_buffers;
-};
-
 #define MFX_IMPL_VIA_MASK(impl) (0x0f00 & (impl))
 
 static const AVRational default_tb = { 1, 90000 };
@@ -172,7 +140,7 @@ int ff_qsvvpp_print_warning(void *log_ct
     const char *desc;
     int ret;
     ret = qsv_map_error(err, &desc);
-    av_log(log_ctx, AV_LOG_WARNING, "%s: %s (%d)\n", warning_string, desc, err);
+    av_log(log_ctx, AV_LOG_VERBOSE, "%s: %s (%d)\n", warning_string, desc, err);
     return ret;
 }
 
@@ -329,6 +297,14 @@ static int fill_frameinfo_by_link(mfxFra
     frameinfo->CropH          = link->h;
     frameinfo->FrameRateExtN  = link->frame_rate.num;
     frameinfo->FrameRateExtD  = link->frame_rate.den;
+
+    /* Apparently VPP in the SDK requires the frame rate to be set to some value, otherwise
+     * init will fail */
+    if (frameinfo->FrameRateExtD == 0 || frameinfo->FrameRateExtN == 0) {
+        frameinfo->FrameRateExtN = 25;
+        frameinfo->FrameRateExtD = 1;
+    }
+
     frameinfo->AspectRatioW   = link->sample_aspect_ratio.num ? link->sample_aspect_ratio.num : 1;
     frameinfo->AspectRatioH   = link->sample_aspect_ratio.den ? link->sample_aspect_ratio.den : 1;
 
@@ -338,9 +314,11 @@ static int fill_frameinfo_by_link(mfxFra
 static void clear_unused_frames(QSVFrame *list)
 {
     while (list) {
-        if (list->surface && !list->surface->Data.Locked) {
-            list->surface = NULL;
+        /* list->queued==1 means the frame is not cached in VPP
+         * process any more, it can be released to pool. */
+        if ((list->queued == 1) && !list->surface.Data.Locked) {
             av_frame_free(&list->frame);
+            list->queued = 0;
         }
         list = list->next;
     }
@@ -363,8 +341,10 @@ static QSVFrame *get_free_frame(QSVFrame
     QSVFrame *out = *list;
 
     for (; out; out = out->next) {
-        if (!out->surface)
+        if (!out->queued) {
+            out->queued = 1;
             break;
+        }
     }
 
     if (!out) {
@@ -373,8 +353,9 @@ static QSVFrame *get_free_frame(QSVFrame
             av_log(NULL, AV_LOG_ERROR, "Can't alloc new output frame.\n");
             return NULL;
         }
-        out->next  = *list;
-        *list      = out;
+        out->queued = 1;
+        out->next   = *list;
+        *list       = out;
     }
 
     return out;
@@ -404,7 +385,7 @@ static QSVFrame *submit_frame(QSVVPPCont
             return NULL;
         }
         qsv_frame->frame   = av_frame_clone(picref);
-        qsv_frame->surface = (mfxFrameSurface1 *)qsv_frame->frame->data[3];
+        qsv_frame->surface = *(mfxFrameSurface1 *)qsv_frame->frame->data[3];
     } else {
         /* make a copy if the input is not padded as libmfx requires */
         if (picref->height & 31 || picref->linesize[0] & 31) {
@@ -427,27 +408,26 @@ static QSVFrame *submit_frame(QSVVPPCont
             qsv_frame->frame = av_frame_clone(picref);
 
         if (map_frame_to_surface(qsv_frame->frame,
-                                &qsv_frame->surface_internal) < 0) {
+                                 &qsv_frame->surface) < 0) {
             av_log(ctx, AV_LOG_ERROR, "Unsupported frame.\n");
             return NULL;
         }
-        qsv_frame->surface = &qsv_frame->surface_internal;
     }
 
-    qsv_frame->surface->Info           = s->frame_infos[FF_INLINK_IDX(inlink)];
-    qsv_frame->surface->Data.TimeStamp = av_rescale_q(qsv_frame->frame->pts,
+    qsv_frame->surface.Info           = s->frame_infos[FF_INLINK_IDX(inlink)];
+    qsv_frame->surface.Data.TimeStamp = av_rescale_q(qsv_frame->frame->pts,
                                                       inlink->time_base, default_tb);
 
-    qsv_frame->surface->Info.PicStruct =
+    qsv_frame->surface.Info.PicStruct =
             !qsv_frame->frame->interlaced_frame ? MFX_PICSTRUCT_PROGRESSIVE :
             (qsv_frame->frame->top_field_first ? MFX_PICSTRUCT_FIELD_TFF :
                                                  MFX_PICSTRUCT_FIELD_BFF);
     if (qsv_frame->frame->repeat_pict == 1)
-        qsv_frame->surface->Info.PicStruct |= MFX_PICSTRUCT_FIELD_REPEATED;
+        qsv_frame->surface.Info.PicStruct |= MFX_PICSTRUCT_FIELD_REPEATED;
     else if (qsv_frame->frame->repeat_pict == 2)
-        qsv_frame->surface->Info.PicStruct |= MFX_PICSTRUCT_FRAME_DOUBLING;
+        qsv_frame->surface.Info.PicStruct |= MFX_PICSTRUCT_FRAME_DOUBLING;
     else if (qsv_frame->frame->repeat_pict == 4)
-        qsv_frame->surface->Info.PicStruct |= MFX_PICSTRUCT_FRAME_TRIPLING;
+        qsv_frame->surface.Info.PicStruct |= MFX_PICSTRUCT_FRAME_TRIPLING;
 
     return qsv_frame;
 }
@@ -478,7 +458,7 @@ static QSVFrame *query_frame(QSVVPPConte
             return NULL;
         }
 
-        out_frame->surface = (mfxFrameSurface1 *)out_frame->frame->data[3];
+        out_frame->surface = *(mfxFrameSurface1 *)out_frame->frame->data[3];
     } else {
         /* Get a frame with aligned dimensions.
          * Libmfx need system memory being 128x64 aligned */
@@ -489,16 +469,14 @@ static QSVFrame *query_frame(QSVVPPConte
             return NULL;
 
         ret = map_frame_to_surface(out_frame->frame,
-                                  &out_frame->surface_internal);
+                                   &out_frame->surface);
         if (ret < 0)
             return NULL;
-
-        out_frame->surface = &out_frame->surface_internal;
     }
 
     out_frame->frame->width  = outlink->w;
     out_frame->frame->height = outlink->h;
-    out_frame->surface->Info = s->vpp_param.vpp.Out;
+    out_frame->surface.Info = s->vpp_param.vpp.Out;
 
     return out_frame;
 }
@@ -671,16 +649,23 @@ static int init_vpp_session(AVFilterCont
     return 0;
 }
 
-int ff_qsvvpp_create(AVFilterContext *avctx, QSVVPPContext **vpp, QSVVPPParam *param)
+static unsigned int qsv_fifo_item_size(void)
+{
+    return sizeof(mfxSyncPoint) + sizeof(QSVFrame*);
+}
+
+static unsigned int qsv_fifo_size(const AVFifoBuffer* fifo)
+{
+    return  av_fifo_size(fifo)/qsv_fifo_item_size();
+}
+
+int ff_qsvvpp_init(AVFilterContext *avctx, QSVVPPParam *param)
 {
     int i;
     int ret;
-    QSVVPPContext *s;
-
-    s = av_mallocz(sizeof(*s));
-    if (!s)
-        return AVERROR(ENOMEM);
+    QSVVPPContext *s = avctx->priv;
 
+    s->last_in_pts   = AV_NOPTS_VALUE;
     s->filter_frame  = param->filter_frame;
     if (!s->filter_frame)
         s->filter_frame = ff_filter_frame;
@@ -743,7 +728,16 @@ int ff_qsvvpp_create(AVFilterContext *av
         s->vpp_param.ExtParam    = param->ext_buf;
     }
 
-    s->vpp_param.AsyncDepth = 1;
+    s->got_frame = 0;
+
+    /** keep fifo size at least 1. Even when async_depth is 0, fifo is used. */
+    s->async_fifo  = av_fifo_alloc((s->async_depth + 1) * qsv_fifo_item_size());
+    if (!s->async_fifo) {
+        ret = AVERROR(ENOMEM);
+        goto failed;
+    }
+
+    s->vpp_param.AsyncDepth = s->async_depth;
 
     if (IS_SYSTEM_MEMORY(s->in_mem_mode))
         s->vpp_param.IOPattern |= MFX_IOPATTERN_IN_SYSTEM_MEMORY;
@@ -770,27 +764,26 @@ int ff_qsvvpp_create(AVFilterContext *av
     } else if (ret > 0)
         ff_qsvvpp_print_warning(avctx, ret, "Warning When creating qsvvpp");
 
-    *vpp = s;
     return 0;
 
 failed:
-    ff_qsvvpp_free(&s);
+    ff_qsvvpp_close(avctx);
 
     return ret;
 }
 
-int ff_qsvvpp_free(QSVVPPContext **vpp)
+int ff_qsvvpp_close(AVFilterContext *avctx)
 {
-    QSVVPPContext *s = *vpp;
-
-    if (!s)
-        return 0;
+    QSVVPPContext *s = avctx->priv;
 
     if (s->session) {
         MFXVideoVPP_Close(s->session);
         MFXClose(s->session);
+        s->session = NULL;
     }
 
+    s->last_in_pts = AV_NOPTS_VALUE;
+
     /* release all the resources */
     clear_frame_list(&s->in_frame_list);
     clear_frame_list(&s->out_frame_list);
@@ -798,7 +791,7 @@ int ff_qsvvpp_free(QSVVPPContext **vpp)
     av_freep(&s->surface_ptrs_out);
     av_freep(&s->ext_buffers);
     av_freep(&s->frame_infos);
-    av_freep(vpp);
+    av_fifo_free(s->async_fifo);
 
     return 0;
 }
@@ -808,8 +801,29 @@ int ff_qsvvpp_filter_frame(QSVVPPContext
     AVFilterContext  *ctx     = inlink->dst;
     AVFilterLink     *outlink = ctx->outputs[0];
     mfxSyncPoint      sync;
-    QSVFrame         *in_frame, *out_frame;
-    int               ret, filter_ret;
+    QSVFrame         *in_frame, *out_frame, *tmp;
+    int               ret, ret1, filter_ret;
+    int64_t           dpts = 0;
+
+    while (s->eof && qsv_fifo_size(s->async_fifo)) {
+        av_fifo_generic_read(s->async_fifo, &tmp, sizeof(tmp), NULL);
+        av_fifo_generic_read(s->async_fifo, &sync, sizeof(sync), NULL);
+        if (MFXVideoCORE_SyncOperation(s->session, sync, 1000) < 0)
+            av_log(ctx, AV_LOG_WARNING, "Sync failed.\n");
+
+        filter_ret = s->filter_frame(outlink, tmp->frame);
+        if (filter_ret < 0) {
+            av_frame_free(&tmp->frame);
+            ret = filter_ret;
+            break;
+        }
+        tmp->queued--;
+        s->got_frame = 1;
+        tmp->frame = NULL;
+    };
+
+    if (!picref)
+        return 0;
 
     in_frame = submit_frame(s, inlink, picref);
     if (!in_frame) {
@@ -826,8 +840,8 @@ int ff_qsvvpp_filter_frame(QSVVPPContext
         }
 
         do {
-            ret = MFXVideoVPP_RunFrameVPPAsync(s->session, in_frame->surface,
-                                               out_frame->surface, NULL, &sync);
+            ret = MFXVideoVPP_RunFrameVPPAsync(s->session, &in_frame->surface,
+                                               &out_frame->surface, NULL, &sync);
             if (ret == MFX_WRN_DEVICE_BUSY)
                 av_usleep(500);
         } while (ret == MFX_WRN_DEVICE_BUSY);
@@ -839,20 +853,63 @@ int ff_qsvvpp_filter_frame(QSVVPPContext
             break;
         }
 
-        if (MFXVideoCORE_SyncOperation(s->session, sync, 1000) < 0)
-            av_log(ctx, AV_LOG_WARNING, "Sync failed.\n");
+        if (in_frame->frame->color_primaries != -1)
+            out_frame->frame->color_primaries = in_frame->frame->color_primaries;
+        if (in_frame->frame->color_trc != -1)
+            out_frame->frame->color_trc = in_frame->frame->color_trc;
+        if (in_frame->frame->colorspace != -1)
+            out_frame->frame->colorspace = in_frame->frame->colorspace;
+        if (in_frame->frame->color_range != -1)
+            out_frame->frame->color_range = in_frame->frame->color_range;
 
-        out_frame->frame->pts = av_rescale_q(out_frame->surface->Data.TimeStamp,
-                                             default_tb, outlink->time_base);
+        ret = av_frame_copy_side_data(out_frame->frame, in_frame->frame, 0);
+        if (ret < 0)
+            return ret;
 
-        filter_ret = s->filter_frame(outlink, out_frame->frame);
-        if (filter_ret < 0) {
-            av_frame_free(&out_frame->frame);
-            ret = filter_ret;
-            break;
+        /* TODO: calculate the PTS for other cases */
+        if (s->deinterlace_enabled &&
+            s->last_in_pts != AV_NOPTS_VALUE &&
+            ret == MFX_ERR_MORE_SURFACE &&
+            out_frame->surface.Data.TimeStamp == MFX_TIMESTAMP_UNKNOWN)
+            dpts = (in_frame->frame->pts - s->last_in_pts) / 2;
+        else
+            dpts = 0;
+
+        out_frame->frame->pts = av_rescale_q(in_frame->frame->pts - dpts,
+                                             inlink->time_base,
+                                             outlink->time_base);
+
+        out_frame->queued++;
+        av_fifo_generic_write(s->async_fifo, &out_frame, sizeof(out_frame), NULL);
+        av_fifo_generic_write(s->async_fifo, &sync, sizeof(sync), NULL);
+
+        if (qsv_fifo_size(s->async_fifo) > s->async_depth) {
+            av_fifo_generic_read(s->async_fifo, &tmp, sizeof(tmp), NULL);
+            av_fifo_generic_read(s->async_fifo, &sync, sizeof(sync), NULL);
+
+            do {
+                ret1 = MFXVideoCORE_SyncOperation(s->session, sync, 1000);
+            } while (ret1 == MFX_WRN_IN_EXECUTION);
+
+            if (ret1 < 0) {
+                ret = ret1;
+                break;
+            }
+
+            filter_ret = s->filter_frame(outlink, tmp->frame);
+            if (filter_ret < 0) {
+                av_frame_free(&tmp->frame);
+                ret = filter_ret;
+                break;
+            }
+
+            tmp->queued--;
+            s->got_frame = 1;
+            tmp->frame = NULL;
         }
-        out_frame->frame = NULL;
-    } while(ret == MFX_ERR_MORE_SURFACE);
+    } while (ret == MFX_ERR_MORE_SURFACE);
+
+    s->last_in_pts = in_frame->frame->pts;
 
     return ret;
 }
Index: jellyfin-ffmpeg/libavfilter/qsvvpp.h
===================================================================
--- libavfilter/qsvvpp.h
+++ libavfilter/qsvvpp.h
@@ -27,6 +27,7 @@
 #include <mfx/mfxvideo.h>
 
 #include "avfilter.h"
+#include "libavutil/fifo.h"
 
 #define FF_INLINK_IDX(link)  ((int)((link)->dstpad - (link)->dst->input_pads))
 #define FF_OUTLINK_IDX(link) ((int)((link)->srcpad - (link)->src->output_pads))
@@ -39,7 +40,46 @@
     ((MFX_VERSION.Major > (MAJOR)) ||                           \
     (MFX_VERSION.Major == (MAJOR) && MFX_VERSION.Minor >= (MINOR)))
 
-typedef struct QSVVPPContext QSVVPPContext;
+typedef struct QSVFrame {
+    AVFrame          *frame;
+    mfxFrameSurface1 surface;
+    struct QSVFrame  *next;
+    int queued;
+} QSVFrame;
+
+typedef struct QSVVPPContext {
+    const AVClass      *class;
+
+    mfxSession          session;
+    int (*filter_frame) (AVFilterLink *outlink, AVFrame *frame); /**< callback */
+    enum AVPixelFormat  out_sw_format;   /**< Real output format */
+    mfxVideoParam       vpp_param;
+    mfxFrameInfo       *frame_infos;     /**< frame info for each input */
+
+    /** members related to the input/output surface */
+    int                 in_mem_mode;
+    int                 out_mem_mode;
+    QSVFrame           *in_frame_list;
+    QSVFrame           *out_frame_list;
+    int                 nb_surface_ptrs_in;
+    int                 nb_surface_ptrs_out;
+    mfxFrameSurface1  **surface_ptrs_in;
+    mfxFrameSurface1  **surface_ptrs_out;
+
+    /** MFXVPP extern parameters */
+    mfxExtOpaqueSurfaceAlloc opaque_alloc;
+    mfxExtBuffer      **ext_buffers;
+    int                 nb_ext_buffers;
+
+    int got_frame;
+    int async_depth;
+    int eof;
+    int deinterlace_enabled;
+    /** order with frame_out, sync */
+    AVFifoBuffer *async_fifo;
+
+    int64_t last_in_pts;
+} QSVVPPContext;
 
 typedef struct QSVVPPCrop {
     int in_idx;        ///< Input index
@@ -63,10 +103,10 @@ typedef struct QSVVPPParam {
 } QSVVPPParam;
 
 /* create and initialize the QSV session */
-int ff_qsvvpp_create(AVFilterContext *avctx, QSVVPPContext **vpp, QSVVPPParam *param);
+int ff_qsvvpp_init(AVFilterContext *avctx, QSVVPPParam *param);
 
 /* release the resources (eg.surfaces) */
-int ff_qsvvpp_free(QSVVPPContext **vpp);
+int ff_qsvvpp_close(AVFilterContext *avctx);
 
 /* vpp filter frame and call the cb if needed */
 int ff_qsvvpp_filter_frame(QSVVPPContext *vpp, AVFilterLink *inlink, AVFrame *frame);
Index: jellyfin-ffmpeg/libavfilter/vf_deinterlace_qsv.c
===================================================================
--- libavfilter/vf_deinterlace_qsv.c
+++ /dev/null
@@ -1,625 +0,0 @@
-/*
- * This file is part of FFmpeg.
- *
- * FFmpeg is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Lesser General Public
- * License as published by the Free Software Foundation; either
- * version 2.1 of the License, or (at your option) any later version.
- *
- * FFmpeg is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with FFmpeg; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
- */
-
-/**
- * @file
- * deinterlace video filter - QSV
- */
-
-#include <mfx/mfxvideo.h>
-
-#include <stdio.h>
-#include <string.h>
-
-#include "libavutil/avstring.h"
-#include "libavutil/common.h"
-#include "libavutil/hwcontext.h"
-#include "libavutil/hwcontext_qsv.h"
-#include "libavutil/internal.h"
-#include "libavutil/mathematics.h"
-#include "libavutil/opt.h"
-#include "libavutil/pixdesc.h"
-#include "libavutil/time.h"
-#include "libavfilter/qsvvpp.h"
-
-#include "avfilter.h"
-#include "formats.h"
-#include "internal.h"
-#include "video.h"
-
-#define MFX_IMPL_VIA_MASK(impl) (0x0f00 & (impl))
-
-enum {
-    QSVDEINT_MORE_OUTPUT = 1,
-    QSVDEINT_MORE_INPUT,
-};
-
-typedef struct QSVFrame {
-    AVFrame *frame;
-    mfxFrameSurface1 surface;
-    int used;
-
-    struct QSVFrame *next;
-} QSVFrame;
-
-typedef struct QSVDeintContext {
-    const AVClass *class;
-
-    AVBufferRef *hw_frames_ctx;
-    /* a clone of the main session, used internally for deinterlacing */
-    mfxSession   session;
-
-    mfxMemId *mem_ids;
-    int    nb_mem_ids;
-
-    mfxFrameSurface1 **surface_ptrs;
-    int             nb_surface_ptrs;
-
-    mfxExtOpaqueSurfaceAlloc opaque_alloc;
-    mfxExtVPPDeinterlacing   deint_conf;
-    mfxExtBuffer            *ext_buffers[2];
-    int                      num_ext_buffers;
-
-    QSVFrame *work_frames;
-
-    int64_t last_pts;
-
-    int eof;
-
-    /* option for Deinterlacing algorithm to be used */
-    int mode;
-} QSVDeintContext;
-
-static av_cold void qsvdeint_uninit(AVFilterContext *ctx)
-{
-    QSVDeintContext *s = ctx->priv;
-    QSVFrame *cur;
-
-    if (s->session) {
-        MFXClose(s->session);
-        s->session = NULL;
-    }
-    av_buffer_unref(&s->hw_frames_ctx);
-
-    cur = s->work_frames;
-    while (cur) {
-        s->work_frames = cur->next;
-        av_frame_free(&cur->frame);
-        av_freep(&cur);
-        cur = s->work_frames;
-    }
-
-    av_freep(&s->mem_ids);
-    s->nb_mem_ids = 0;
-
-    av_freep(&s->surface_ptrs);
-    s->nb_surface_ptrs = 0;
-}
-
-static int qsvdeint_query_formats(AVFilterContext *ctx)
-{
-    static const enum AVPixelFormat pixel_formats[] = {
-        AV_PIX_FMT_QSV, AV_PIX_FMT_NONE,
-    };
-    AVFilterFormats *pix_fmts  = ff_make_format_list(pixel_formats);
-    int ret;
-
-    if ((ret = ff_set_common_formats(ctx, pix_fmts)) < 0)
-        return ret;
-
-    return 0;
-}
-
-static mfxStatus frame_alloc(mfxHDL pthis, mfxFrameAllocRequest *req,
-                             mfxFrameAllocResponse *resp)
-{
-    AVFilterContext *ctx = pthis;
-    QSVDeintContext   *s = ctx->priv;
-
-    if (!(req->Type & MFX_MEMTYPE_VIDEO_MEMORY_PROCESSOR_TARGET) ||
-        !(req->Type & (MFX_MEMTYPE_FROM_VPPIN | MFX_MEMTYPE_FROM_VPPOUT)) ||
-        !(req->Type & MFX_MEMTYPE_EXTERNAL_FRAME))
-        return MFX_ERR_UNSUPPORTED;
-
-    resp->mids           = s->mem_ids;
-    resp->NumFrameActual = s->nb_mem_ids;
-
-    return MFX_ERR_NONE;
-}
-
-static mfxStatus frame_free(mfxHDL pthis, mfxFrameAllocResponse *resp)
-{
-    return MFX_ERR_NONE;
-}
-
-static mfxStatus frame_lock(mfxHDL pthis, mfxMemId mid, mfxFrameData *ptr)
-{
-    return MFX_ERR_UNSUPPORTED;
-}
-
-static mfxStatus frame_unlock(mfxHDL pthis, mfxMemId mid, mfxFrameData *ptr)
-{
-    return MFX_ERR_UNSUPPORTED;
-}
-
-static mfxStatus frame_get_hdl(mfxHDL pthis, mfxMemId mid, mfxHDL *hdl)
-{
-    mfxHDLPair *pair_dst = (mfxHDLPair*)hdl;
-    mfxHDLPair *pair_src = (mfxHDLPair*)mid;
-
-    pair_dst->first = pair_src->first;
-
-    if (pair_src->second != (mfxMemId)MFX_INFINITE)
-        pair_dst->second = pair_src->second;
-    return MFX_ERR_NONE;
-}
-
-static int init_out_session(AVFilterContext *ctx)
-{
-
-    QSVDeintContext                  *s = ctx->priv;
-    AVHWFramesContext    *hw_frames_ctx = (AVHWFramesContext*)s->hw_frames_ctx->data;
-    AVQSVFramesContext *hw_frames_hwctx = hw_frames_ctx->hwctx;
-    AVQSVDeviceContext    *device_hwctx = hw_frames_ctx->device_ctx->hwctx;
-
-    int opaque = !!(hw_frames_hwctx->frame_type & MFX_MEMTYPE_OPAQUE_FRAME);
-
-    mfxHDL handle = NULL;
-    mfxHandleType handle_type;
-    mfxVersion ver;
-    mfxIMPL impl;
-    mfxVideoParam par;
-    mfxStatus err;
-    int i;
-
-    /* extract the properties of the "master" session given to us */
-    err = MFXQueryIMPL(device_hwctx->session, &impl);
-    if (err == MFX_ERR_NONE)
-        err = MFXQueryVersion(device_hwctx->session, &ver);
-    if (err != MFX_ERR_NONE) {
-        av_log(ctx, AV_LOG_ERROR, "Error querying the session attributes\n");
-        return AVERROR_UNKNOWN;
-    }
-
-    if (MFX_IMPL_VIA_VAAPI == MFX_IMPL_VIA_MASK(impl)) {
-        handle_type = MFX_HANDLE_VA_DISPLAY;
-    } else if (MFX_IMPL_VIA_D3D11 == MFX_IMPL_VIA_MASK(impl)) {
-        handle_type = MFX_HANDLE_D3D11_DEVICE;
-    } else if (MFX_IMPL_VIA_D3D9 == MFX_IMPL_VIA_MASK(impl)) {
-        handle_type = MFX_HANDLE_D3D9_DEVICE_MANAGER;
-    } else {
-        av_log(ctx, AV_LOG_ERROR, "Error unsupported handle type\n");
-        return AVERROR_UNKNOWN;
-    }
-
-    err = MFXVideoCORE_GetHandle(device_hwctx->session, handle_type, &handle);
-    if (err < 0)
-        return ff_qsvvpp_print_error(ctx, err, "Error getting the session handle");
-    else if (err > 0) {
-        ff_qsvvpp_print_warning(ctx, err, "Warning in getting the session handle");
-        return AVERROR_UNKNOWN;
-    }
-
-    /* create a "slave" session with those same properties, to be used for
-     * actual deinterlacing */
-    err = MFXInit(impl, &ver, &s->session);
-    if (err < 0)
-        return ff_qsvvpp_print_error(ctx, err, "Error initializing a session for deinterlacing");
-    else if (err > 0) {
-        ff_qsvvpp_print_warning(ctx, err, "Warning in session initialization");
-        return AVERROR_UNKNOWN;
-    }
-
-    if (handle) {
-        err = MFXVideoCORE_SetHandle(s->session, handle_type, handle);
-        if (err != MFX_ERR_NONE)
-            return AVERROR_UNKNOWN;
-    }
-
-    if (QSV_RUNTIME_VERSION_ATLEAST(ver, 1, 25)) {
-        err = MFXJoinSession(device_hwctx->session, s->session);
-        if (err != MFX_ERR_NONE)
-            return AVERROR_UNKNOWN;
-    }
-
-    memset(&par, 0, sizeof(par));
-
-    s->deint_conf.Header.BufferId = MFX_EXTBUFF_VPP_DEINTERLACING;
-    s->deint_conf.Header.BufferSz = sizeof(s->deint_conf);
-    s->deint_conf.Mode = s->mode;
-
-    s->ext_buffers[s->num_ext_buffers++] = (mfxExtBuffer *)&s->deint_conf;
-
-    if (opaque) {
-        s->surface_ptrs = av_mallocz_array(hw_frames_hwctx->nb_surfaces,
-                                           sizeof(*s->surface_ptrs));
-        if (!s->surface_ptrs)
-            return AVERROR(ENOMEM);
-        for (i = 0; i < hw_frames_hwctx->nb_surfaces; i++)
-            s->surface_ptrs[i] = hw_frames_hwctx->surfaces + i;
-        s->nb_surface_ptrs = hw_frames_hwctx->nb_surfaces;
-
-        s->opaque_alloc.In.Surfaces   = s->surface_ptrs;
-        s->opaque_alloc.In.NumSurface = s->nb_surface_ptrs;
-        s->opaque_alloc.In.Type       = hw_frames_hwctx->frame_type;
-
-        s->opaque_alloc.Out = s->opaque_alloc.In;
-
-        s->opaque_alloc.Header.BufferId = MFX_EXTBUFF_OPAQUE_SURFACE_ALLOCATION;
-        s->opaque_alloc.Header.BufferSz = sizeof(s->opaque_alloc);
-
-        s->ext_buffers[s->num_ext_buffers++] = (mfxExtBuffer *)&s->opaque_alloc;
-
-        par.IOPattern = MFX_IOPATTERN_IN_OPAQUE_MEMORY | MFX_IOPATTERN_OUT_OPAQUE_MEMORY;
-    } else {
-        mfxFrameAllocator frame_allocator = {
-            .pthis  = ctx,
-            .Alloc  = frame_alloc,
-            .Lock   = frame_lock,
-            .Unlock = frame_unlock,
-            .GetHDL = frame_get_hdl,
-            .Free   = frame_free,
-        };
-
-        s->mem_ids = av_mallocz_array(hw_frames_hwctx->nb_surfaces,
-                                      sizeof(*s->mem_ids));
-        if (!s->mem_ids)
-            return AVERROR(ENOMEM);
-        for (i = 0; i < hw_frames_hwctx->nb_surfaces; i++)
-            s->mem_ids[i] = hw_frames_hwctx->surfaces[i].Data.MemId;
-        s->nb_mem_ids = hw_frames_hwctx->nb_surfaces;
-
-        err = MFXVideoCORE_SetFrameAllocator(s->session, &frame_allocator);
-        if (err != MFX_ERR_NONE)
-            return AVERROR_UNKNOWN;
-
-        par.IOPattern = MFX_IOPATTERN_IN_VIDEO_MEMORY | MFX_IOPATTERN_OUT_VIDEO_MEMORY;
-    }
-
-    par.ExtParam    = s->ext_buffers;
-    par.NumExtParam = s->num_ext_buffers;
-
-    par.AsyncDepth = 1;    // TODO async
-
-    par.vpp.In = hw_frames_hwctx->surfaces[0].Info;
-
-    par.vpp.In.CropW = ctx->inputs[0]->w;
-    par.vpp.In.CropH = ctx->inputs[0]->h;
-
-    if (ctx->inputs[0]->frame_rate.num) {
-        par.vpp.In.FrameRateExtN = ctx->inputs[0]->frame_rate.num;
-        par.vpp.In.FrameRateExtD = ctx->inputs[0]->frame_rate.den;
-    } else {
-        par.vpp.In.FrameRateExtN = ctx->inputs[0]->time_base.num;
-        par.vpp.In.FrameRateExtD = ctx->inputs[0]->time_base.den;
-    }
-
-    par.vpp.Out = par.vpp.In;
-
-    if (ctx->outputs[0]->frame_rate.num) {
-        par.vpp.Out.FrameRateExtN = ctx->outputs[0]->frame_rate.num;
-        par.vpp.Out.FrameRateExtD = ctx->outputs[0]->frame_rate.den;
-    } else {
-        par.vpp.Out.FrameRateExtN = ctx->outputs[0]->time_base.num;
-        par.vpp.Out.FrameRateExtD = ctx->outputs[0]->time_base.den;
-    }
-
-    /* Print input memory mode */
-    ff_qsvvpp_print_iopattern(ctx, par.IOPattern & 0x0F, "VPP");
-    /* Print output memory mode */
-    ff_qsvvpp_print_iopattern(ctx, par.IOPattern & 0xF0, "VPP");
-    err = MFXVideoVPP_Init(s->session, &par);
-    if (err < 0)
-        return ff_qsvvpp_print_error(ctx, err,
-                                     "Error opening the VPP for deinterlacing");
-    else if (err > 0) {
-        ff_qsvvpp_print_warning(ctx, err,
-                                "Warning in VPP initialization");
-        return AVERROR_UNKNOWN;
-    }
-
-    return 0;
-}
-
-static int qsvdeint_config_props(AVFilterLink *outlink)
-{
-    AVFilterContext *ctx = outlink->src;
-    AVFilterLink *inlink = ctx->inputs[0];
-    QSVDeintContext  *s = ctx->priv;
-    int ret;
-
-    qsvdeint_uninit(ctx);
-
-    s->last_pts = AV_NOPTS_VALUE;
-    outlink->frame_rate = av_mul_q(inlink->frame_rate,
-                                   (AVRational){ 2, 1 });
-    outlink->time_base  = av_mul_q(inlink->time_base,
-                                   (AVRational){ 1, 2 });
-
-    /* check that we have a hw context */
-    if (!inlink->hw_frames_ctx) {
-        av_log(ctx, AV_LOG_ERROR, "No hw context provided on input\n");
-        return AVERROR(EINVAL);
-    }
-
-    s->hw_frames_ctx = av_buffer_ref(inlink->hw_frames_ctx);
-    if (!s->hw_frames_ctx)
-        return AVERROR(ENOMEM);
-
-    av_buffer_unref(&outlink->hw_frames_ctx);
-    outlink->hw_frames_ctx = av_buffer_ref(inlink->hw_frames_ctx);
-    if (!outlink->hw_frames_ctx) {
-        qsvdeint_uninit(ctx);
-        return AVERROR(ENOMEM);
-    }
-
-    ret = init_out_session(ctx);
-    if (ret < 0)
-        return ret;
-
-
-    return 0;
-}
-
-static void clear_unused_frames(QSVDeintContext *s)
-{
-    QSVFrame *cur = s->work_frames;
-    while (cur) {
-        if (!cur->surface.Data.Locked) {
-            av_frame_free(&cur->frame);
-            cur->used = 0;
-        }
-        cur = cur->next;
-    }
-}
-
-static int get_free_frame(QSVDeintContext *s, QSVFrame **f)
-{
-    QSVFrame *frame, **last;
-
-    clear_unused_frames(s);
-
-    frame = s->work_frames;
-    last  = &s->work_frames;
-    while (frame) {
-        if (!frame->used) {
-            *f = frame;
-            return 0;
-        }
-
-        last  = &frame->next;
-        frame = frame->next;
-    }
-
-    frame = av_mallocz(sizeof(*frame));
-    if (!frame)
-        return AVERROR(ENOMEM);
-    *last = frame;
-    *f    = frame;
-
-    return 0;
-}
-
-static int submit_frame(AVFilterContext *ctx, AVFrame *frame,
-                        mfxFrameSurface1 **surface)
-{
-    QSVDeintContext *s = ctx->priv;
-    QSVFrame *qf;
-    int ret;
-
-    ret = get_free_frame(s, &qf);
-    if (ret < 0)
-        return ret;
-
-    qf->frame = frame;
-
-    qf->surface = *(mfxFrameSurface1*)qf->frame->data[3];
-
-    qf->surface.Data.Locked = 0;
-    qf->surface.Info.CropW  = qf->frame->width;
-    qf->surface.Info.CropH  = qf->frame->height;
-
-    qf->surface.Info.PicStruct = !qf->frame->interlaced_frame ? MFX_PICSTRUCT_PROGRESSIVE :
-                                 (qf->frame->top_field_first ? MFX_PICSTRUCT_FIELD_TFF :
-                                                           MFX_PICSTRUCT_FIELD_BFF);
-    if (qf->frame->repeat_pict == 1) {
-        qf->surface.Info.PicStruct |= MFX_PICSTRUCT_FIELD_REPEATED;
-        qf->surface.Info.PicStruct |= qf->frame->top_field_first ? MFX_PICSTRUCT_FIELD_TFF :
-                                                            MFX_PICSTRUCT_FIELD_BFF;
-    } else if (qf->frame->repeat_pict == 2)
-        qf->surface.Info.PicStruct |= MFX_PICSTRUCT_FRAME_DOUBLING;
-    else if (qf->frame->repeat_pict == 4)
-        qf->surface.Info.PicStruct |= MFX_PICSTRUCT_FRAME_TRIPLING;
-
-    if (ctx->inputs[0]->frame_rate.num) {
-        qf->surface.Info.FrameRateExtN = ctx->inputs[0]->frame_rate.num;
-        qf->surface.Info.FrameRateExtD = ctx->inputs[0]->frame_rate.den;
-    } else {
-        qf->surface.Info.FrameRateExtN = ctx->inputs[0]->time_base.num;
-        qf->surface.Info.FrameRateExtD = ctx->inputs[0]->time_base.den;
-    }
-
-    qf->surface.Data.TimeStamp = av_rescale_q(qf->frame->pts,
-                                              ctx->inputs[0]->time_base,
-                                              (AVRational){1, 90000});
-
-    *surface = &qf->surface;
-    qf->used = 1;
-
-    return 0;
-}
-
-static int process_frame(AVFilterContext *ctx, const AVFrame *in,
-                         mfxFrameSurface1 *surf_in)
-{
-    QSVDeintContext    *s = ctx->priv;
-    AVFilterLink  *inlink = ctx->inputs[0];
-    AVFilterLink *outlink = ctx->outputs[0];
-
-    AVFrame *out;
-    mfxFrameSurface1 *surf_out;
-    mfxSyncPoint sync = NULL;
-    mfxStatus err;
-    int ret, again = 0;
-
-    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
-    if (!out) {
-        ret = AVERROR(ENOMEM);
-        goto fail;
-    }
-
-    surf_out = (mfxFrameSurface1*)out->data[3];
-    surf_out->Info.CropW     = outlink->w;
-    surf_out->Info.CropH     = outlink->h;
-    surf_out->Info.PicStruct = MFX_PICSTRUCT_PROGRESSIVE;
-
-    do {
-        err = MFXVideoVPP_RunFrameVPPAsync(s->session, surf_in, surf_out,
-                                           NULL, &sync);
-        if (err == MFX_WRN_DEVICE_BUSY)
-            av_usleep(1);
-    } while (err == MFX_WRN_DEVICE_BUSY);
-
-    if (err == MFX_ERR_MORE_DATA) {
-        av_frame_free(&out);
-        return QSVDEINT_MORE_INPUT;
-    }
-
-    if (err < 0 && err != MFX_ERR_MORE_SURFACE) {
-        ret = ff_qsvvpp_print_error(ctx, err, "Error during deinterlacing");
-        goto fail;
-    }
-
-    if (!sync) {
-        av_log(ctx, AV_LOG_ERROR, "No sync during deinterlacing\n");
-        ret = AVERROR_UNKNOWN;
-        goto fail;
-    }
-    if (err == MFX_ERR_MORE_SURFACE)
-        again = 1;
-
-    do {
-        err = MFXVideoCORE_SyncOperation(s->session, sync, 1000);
-    } while (err == MFX_WRN_IN_EXECUTION);
-    if (err < 0) {
-        ret = ff_qsvvpp_print_error(ctx, err, "Error synchronizing the operation");
-        goto fail;
-    }
-
-    ret = av_frame_copy_props(out, in);
-    if (ret < 0)
-        goto fail;
-
-    out->width            = outlink->w;
-    out->height           = outlink->h;
-    out->interlaced_frame = 0;
-
-    out->pts = av_rescale_q(out->pts, inlink->time_base, outlink->time_base);
-    if (out->pts == s->last_pts)
-        out->pts++;
-    s->last_pts = out->pts;
-
-    ret = ff_filter_frame(outlink, out);
-    if (ret < 0)
-        return ret;
-
-    return again ? QSVDEINT_MORE_OUTPUT : 0;
-fail:
-    av_frame_free(&out);
-    return ret;
-}
-
-static int qsvdeint_filter_frame(AVFilterLink *link, AVFrame *in)
-{
-    AVFilterContext *ctx = link->dst;
-
-    mfxFrameSurface1 *surf_in;
-    int ret;
-
-    ret = submit_frame(ctx, in, &surf_in);
-    if (ret < 0) {
-        av_frame_free(&in);
-        return ret;
-    }
-
-    do {
-        ret = process_frame(ctx, in, surf_in);
-        if (ret < 0)
-            return ret;
-    } while (ret == QSVDEINT_MORE_OUTPUT);
-
-    return 0;
-}
-
-static int qsvdeint_request_frame(AVFilterLink *outlink)
-{
-    AVFilterContext *ctx = outlink->src;
-
-    return ff_request_frame(ctx->inputs[0]);
-}
-
-#define OFFSET(x) offsetof(QSVDeintContext, x)
-#define FLAGS AV_OPT_FLAG_VIDEO_PARAM|AV_OPT_FLAG_FILTERING_PARAM
-static const AVOption options[] = {
-    { "mode", "set deinterlace mode", OFFSET(mode),   AV_OPT_TYPE_INT, {.i64 = MFX_DEINTERLACING_ADVANCED}, MFX_DEINTERLACING_BOB, MFX_DEINTERLACING_ADVANCED, FLAGS, "mode"},
-    { "bob",   "bob algorithm",                  0, AV_OPT_TYPE_CONST,      {.i64 = MFX_DEINTERLACING_BOB}, MFX_DEINTERLACING_BOB, MFX_DEINTERLACING_ADVANCED, FLAGS, "mode"},
-    { "advanced", "Motion adaptive algorithm",   0, AV_OPT_TYPE_CONST, {.i64 = MFX_DEINTERLACING_ADVANCED}, MFX_DEINTERLACING_BOB, MFX_DEINTERLACING_ADVANCED, FLAGS, "mode"},
-    { NULL },
-};
-
-static const AVClass qsvdeint_class = {
-    .class_name = "deinterlace_qsv",
-    .item_name  = av_default_item_name,
-    .option     = options,
-    .version    = LIBAVUTIL_VERSION_INT,
-};
-
-static const AVFilterPad qsvdeint_inputs[] = {
-    {
-        .name         = "default",
-        .type         = AVMEDIA_TYPE_VIDEO,
-        .filter_frame = qsvdeint_filter_frame,
-    },
-    { NULL }
-};
-
-static const AVFilterPad qsvdeint_outputs[] = {
-    {
-        .name          = "default",
-        .type          = AVMEDIA_TYPE_VIDEO,
-        .config_props  = qsvdeint_config_props,
-        .request_frame = qsvdeint_request_frame,
-    },
-    { NULL }
-};
-
-AVFilter ff_vf_deinterlace_qsv = {
-    .name      = "deinterlace_qsv",
-    .description = NULL_IF_CONFIG_SMALL("QuickSync video deinterlacing"),
-
-    .uninit        = qsvdeint_uninit,
-    .query_formats = qsvdeint_query_formats,
-
-    .priv_size = sizeof(QSVDeintContext),
-    .priv_class = &qsvdeint_class,
-
-    .inputs    = qsvdeint_inputs,
-    .outputs   = qsvdeint_outputs,
-
-    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
-};
Index: jellyfin-ffmpeg/libavfilter/vf_overlay_qsv.c
===================================================================
--- libavfilter/vf_overlay_qsv.c
+++ libavfilter/vf_overlay_qsv.c
@@ -58,10 +58,9 @@ enum var_name {
 };
 
 typedef struct QSVOverlayContext {
-    const AVClass      *class;
+    QSVVPPContext      qsv;
 
     FFFrameSync fs;
-    QSVVPPContext      *qsv;
     QSVVPPParam        qsv_param;
     mfxExtVPPComposite comp_conf;
     double             var_values[VAR_VARS_NB];
@@ -231,7 +230,7 @@ static int config_overlay_input(AVFilter
 static int process_frame(FFFrameSync *fs)
 {
     AVFilterContext *ctx = fs->parent;
-    QSVOverlayContext *s = fs->opaque;
+    QSVVPPContext   *qsv = fs->opaque;
     AVFilterLink    *in0 = ctx->inputs[0];
     AVFilterLink    *in1 = ctx->inputs[1];
     AVFrame        *main = NULL;
@@ -249,14 +248,17 @@ static int process_frame(FFFrameSync *fs
         return AVERROR_BUG;
 
     /* composite main frame */
-    ret = ff_qsvvpp_filter_frame(s->qsv, in0, main);
+    ret = ff_qsvvpp_filter_frame(qsv, in0, main);
     if (ret < 0 && ret != AVERROR(EAGAIN))
         return ret;
 
+    /* remove all side data of the overlay frame*/
+    if (overlay)
+        av_frame_remove_all_side_data(overlay);
+
     /* composite overlay frame */
     /* or overwrite main frame again if the overlay frame isn't ready yet */
-    ret = ff_qsvvpp_filter_frame(s->qsv, overlay ? in1 : in0, overlay ? overlay : main);
-    return ret;
+    return ff_qsvvpp_filter_frame(qsv, overlay ? in1 : in0, overlay ? overlay : main);
 }
 
 static int init_framesync(AVFilterContext *ctx)
@@ -300,7 +302,7 @@ static int config_output(AVFilterLink *o
     if (ret < 0)
         return ret;
 
-    return ff_qsvvpp_create(ctx, &vpp->qsv, &vpp->qsv_param);
+    return ff_qsvvpp_init(ctx, &vpp->qsv_param);
 }
 
 /*
@@ -349,7 +351,7 @@ static av_cold void overlay_qsv_uninit(A
 {
     QSVOverlayContext *vpp = ctx->priv;
 
-    ff_qsvvpp_free(&vpp->qsv);
+    ff_qsvvpp_close(ctx);
     ff_framesync_uninit(&vpp->fs);
     av_freep(&vpp->comp_conf.InputStream);
     av_freep(&vpp->qsv_param.ext_buf);
Index: jellyfin-ffmpeg/libavfilter/vf_scale_qsv.c
===================================================================
--- libavfilter/vf_scale_qsv.c
+++ /dev/null
@@ -1,693 +0,0 @@
-/*
- * This file is part of FFmpeg.
- *
- * FFmpeg is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Lesser General Public
- * License as published by the Free Software Foundation; either
- * version 2.1 of the License, or (at your option) any later version.
- *
- * FFmpeg is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with FFmpeg; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
- */
-
-/**
- * @file
- * scale video filter - QSV
- */
-
-#include <mfx/mfxvideo.h>
-
-#include <stdio.h>
-#include <string.h>
-
-#include "libavutil/avstring.h"
-#include "libavutil/common.h"
-#include "libavutil/eval.h"
-#include "libavutil/hwcontext.h"
-#include "libavutil/hwcontext_qsv.h"
-#include "libavutil/internal.h"
-#include "libavutil/mathematics.h"
-#include "libavutil/opt.h"
-#include "libavutil/pixdesc.h"
-#include "libavutil/time.h"
-#include "libavfilter/qsvvpp.h"
-
-#include "avfilter.h"
-#include "formats.h"
-#include "internal.h"
-#include "video.h"
-
-static const char *const var_names[] = {
-    "PI",
-    "PHI",
-    "E",
-    "in_w",   "iw",
-    "in_h",   "ih",
-    "out_w",  "ow",
-    "out_h",  "oh",
-    "a", "dar",
-    "sar",
-    NULL
-};
-
-enum var_name {
-    VAR_PI,
-    VAR_PHI,
-    VAR_E,
-    VAR_IN_W,   VAR_IW,
-    VAR_IN_H,   VAR_IH,
-    VAR_OUT_W,  VAR_OW,
-    VAR_OUT_H,  VAR_OH,
-    VAR_A, VAR_DAR,
-    VAR_SAR,
-    VARS_NB
-};
-
-#define QSV_HAVE_SCALING_CONFIG  QSV_VERSION_ATLEAST(1, 19)
-#define MFX_IMPL_VIA_MASK(impl) (0x0f00 & (impl))
-
-typedef struct QSVScaleContext {
-    const AVClass *class;
-
-    /* a clone of the main session, used internally for scaling */
-    mfxSession   session;
-
-    mfxMemId *mem_ids_in;
-    int nb_mem_ids_in;
-
-    mfxMemId *mem_ids_out;
-    int nb_mem_ids_out;
-
-    mfxFrameSurface1 **surface_ptrs_in;
-    int             nb_surface_ptrs_in;
-
-    mfxFrameSurface1 **surface_ptrs_out;
-    int             nb_surface_ptrs_out;
-
-    mfxExtOpaqueSurfaceAlloc opaque_alloc;
-
-#if QSV_HAVE_SCALING_CONFIG
-    mfxExtVPPScaling         scale_conf;
-#endif
-    int                      mode;
-
-    mfxExtBuffer             *ext_buffers[1 + QSV_HAVE_SCALING_CONFIG];
-    int                      num_ext_buf;
-
-    int shift_width, shift_height;
-
-    /**
-     * New dimensions. Special values are:
-     *   0 = original width/height
-     *  -1 = keep original aspect
-     */
-    int w, h;
-
-    /**
-     * Output sw format. AV_PIX_FMT_NONE for no conversion.
-     */
-    enum AVPixelFormat format;
-
-    char *w_expr;               ///< width  expression string
-    char *h_expr;               ///< height expression string
-    char *format_str;
-} QSVScaleContext;
-
-static av_cold int qsvscale_init(AVFilterContext *ctx)
-{
-    QSVScaleContext *s = ctx->priv;
-
-    if (!strcmp(s->format_str, "same")) {
-        s->format = AV_PIX_FMT_NONE;
-    } else {
-        s->format = av_get_pix_fmt(s->format_str);
-        if (s->format == AV_PIX_FMT_NONE) {
-            av_log(ctx, AV_LOG_ERROR, "Unrecognized pixel format: %s\n", s->format_str);
-            return AVERROR(EINVAL);
-        }
-    }
-
-    return 0;
-}
-
-static av_cold void qsvscale_uninit(AVFilterContext *ctx)
-{
-    QSVScaleContext *s = ctx->priv;
-
-    if (s->session) {
-        MFXClose(s->session);
-        s->session = NULL;
-    }
-
-    av_freep(&s->mem_ids_in);
-    av_freep(&s->mem_ids_out);
-    s->nb_mem_ids_in  = 0;
-    s->nb_mem_ids_out = 0;
-
-    av_freep(&s->surface_ptrs_in);
-    av_freep(&s->surface_ptrs_out);
-    s->nb_surface_ptrs_in  = 0;
-    s->nb_surface_ptrs_out = 0;
-}
-
-static int qsvscale_query_formats(AVFilterContext *ctx)
-{
-    static const enum AVPixelFormat pixel_formats[] = {
-        AV_PIX_FMT_QSV, AV_PIX_FMT_NONE,
-    };
-    AVFilterFormats *pix_fmts  = ff_make_format_list(pixel_formats);
-    int ret;
-
-    if ((ret = ff_set_common_formats(ctx, pix_fmts)) < 0)
-        return ret;
-
-    return 0;
-}
-
-static int init_out_pool(AVFilterContext *ctx,
-                         int out_width, int out_height)
-{
-    QSVScaleContext *s = ctx->priv;
-    AVFilterLink *outlink = ctx->outputs[0];
-
-    AVHWFramesContext *in_frames_ctx;
-    AVHWFramesContext *out_frames_ctx;
-    AVQSVFramesContext *in_frames_hwctx;
-    AVQSVFramesContext *out_frames_hwctx;
-    enum AVPixelFormat in_format;
-    enum AVPixelFormat out_format;
-    int i, ret;
-
-    /* check that we have a hw context */
-    if (!ctx->inputs[0]->hw_frames_ctx) {
-        av_log(ctx, AV_LOG_ERROR, "No hw context provided on input\n");
-        return AVERROR(EINVAL);
-    }
-    in_frames_ctx   = (AVHWFramesContext*)ctx->inputs[0]->hw_frames_ctx->data;
-    in_frames_hwctx = in_frames_ctx->hwctx;
-
-    in_format     = in_frames_ctx->sw_format;
-    out_format    = (s->format == AV_PIX_FMT_NONE) ? in_format : s->format;
-
-    outlink->hw_frames_ctx = av_hwframe_ctx_alloc(in_frames_ctx->device_ref);
-    if (!outlink->hw_frames_ctx)
-        return AVERROR(ENOMEM);
-    out_frames_ctx   = (AVHWFramesContext*)outlink->hw_frames_ctx->data;
-    out_frames_hwctx = out_frames_ctx->hwctx;
-
-    out_frames_ctx->format            = AV_PIX_FMT_QSV;
-    out_frames_ctx->width             = FFALIGN(out_width,  16);
-    out_frames_ctx->height            = FFALIGN(out_height, 16);
-    out_frames_ctx->sw_format         = out_format;
-    out_frames_ctx->initial_pool_size = 4;
-
-    out_frames_hwctx->frame_type = in_frames_hwctx->frame_type | MFX_MEMTYPE_FROM_VPPOUT;
-
-    ret = ff_filter_init_hw_frames(ctx, outlink, 32);
-    if (ret < 0)
-        return ret;
-
-    ret = av_hwframe_ctx_init(outlink->hw_frames_ctx);
-    if (ret < 0)
-        return ret;
-
-    for (i = 0; i < out_frames_hwctx->nb_surfaces; i++) {
-        mfxFrameInfo *info = &out_frames_hwctx->surfaces[i].Info;
-        info->CropW = out_width;
-        info->CropH = out_height;
-    }
-
-    return 0;
-}
-
-static mfxStatus frame_alloc(mfxHDL pthis, mfxFrameAllocRequest *req,
-                             mfxFrameAllocResponse *resp)
-{
-    AVFilterContext *ctx = pthis;
-    QSVScaleContext   *s = ctx->priv;
-
-    if (!(req->Type & MFX_MEMTYPE_VIDEO_MEMORY_PROCESSOR_TARGET) ||
-        !(req->Type & (MFX_MEMTYPE_FROM_VPPIN | MFX_MEMTYPE_FROM_VPPOUT)) ||
-        !(req->Type & MFX_MEMTYPE_EXTERNAL_FRAME))
-        return MFX_ERR_UNSUPPORTED;
-
-    if (req->Type & MFX_MEMTYPE_FROM_VPPIN) {
-        resp->mids           = s->mem_ids_in;
-        resp->NumFrameActual = s->nb_mem_ids_in;
-    } else {
-        resp->mids           = s->mem_ids_out;
-        resp->NumFrameActual = s->nb_mem_ids_out;
-    }
-
-    return MFX_ERR_NONE;
-}
-
-static mfxStatus frame_free(mfxHDL pthis, mfxFrameAllocResponse *resp)
-{
-    return MFX_ERR_NONE;
-}
-
-static mfxStatus frame_lock(mfxHDL pthis, mfxMemId mid, mfxFrameData *ptr)
-{
-    return MFX_ERR_UNSUPPORTED;
-}
-
-static mfxStatus frame_unlock(mfxHDL pthis, mfxMemId mid, mfxFrameData *ptr)
-{
-    return MFX_ERR_UNSUPPORTED;
-}
-
-static mfxStatus frame_get_hdl(mfxHDL pthis, mfxMemId mid, mfxHDL *hdl)
-{
-    mfxHDLPair *pair_dst = (mfxHDLPair*)hdl;
-    mfxHDLPair *pair_src = (mfxHDLPair*)mid;
-
-    pair_dst->first = pair_src->first;
-
-    if (pair_src->second != (mfxMemId)MFX_INFINITE)
-        pair_dst->second = pair_src->second;
-    return MFX_ERR_NONE;
-}
-
-static int init_out_session(AVFilterContext *ctx, int in_width, int in_height)
-{
-
-    QSVScaleContext                   *s = ctx->priv;
-    AVHWFramesContext     *in_frames_ctx = (AVHWFramesContext*)ctx->inputs[0]->hw_frames_ctx->data;
-    AVHWFramesContext    *out_frames_ctx = (AVHWFramesContext*)ctx->outputs[0]->hw_frames_ctx->data;
-    AVQSVFramesContext  *in_frames_hwctx = in_frames_ctx->hwctx;
-    AVQSVFramesContext *out_frames_hwctx = out_frames_ctx->hwctx;
-    AVQSVDeviceContext     *device_hwctx = in_frames_ctx->device_ctx->hwctx;
-
-    int opaque = !!(in_frames_hwctx->frame_type & MFX_MEMTYPE_OPAQUE_FRAME);
-
-    mfxHDL handle = NULL;
-    mfxHandleType handle_type;
-    mfxVersion ver;
-    mfxIMPL impl;
-    mfxVideoParam par;
-    mfxStatus err;
-    int i;
-
-    s->num_ext_buf = 0;
-
-    /* extract the properties of the "master" session given to us */
-    err = MFXQueryIMPL(device_hwctx->session, &impl);
-    if (err == MFX_ERR_NONE)
-        err = MFXQueryVersion(device_hwctx->session, &ver);
-    if (err != MFX_ERR_NONE) {
-        av_log(ctx, AV_LOG_ERROR, "Error querying the session attributes\n");
-        return AVERROR_UNKNOWN;
-    }
-
-    if (MFX_IMPL_VIA_VAAPI == MFX_IMPL_VIA_MASK(impl)) {
-        handle_type = MFX_HANDLE_VA_DISPLAY;
-    } else if (MFX_IMPL_VIA_D3D11 == MFX_IMPL_VIA_MASK(impl)) {
-        handle_type = MFX_HANDLE_D3D11_DEVICE;
-    } else if (MFX_IMPL_VIA_D3D9 == MFX_IMPL_VIA_MASK(impl)) {
-        handle_type = MFX_HANDLE_D3D9_DEVICE_MANAGER;
-    } else {
-        av_log(ctx, AV_LOG_ERROR, "Error unsupported handle type\n");
-        return AVERROR_UNKNOWN;
-    }
-
-    err = MFXVideoCORE_GetHandle(device_hwctx->session, handle_type, &handle);
-    if (err < 0)
-        return ff_qsvvpp_print_error(ctx, err, "Error getting the session handle");
-    else if (err > 0) {
-        ff_qsvvpp_print_warning(ctx, err, "Warning in getting the session handle");
-        return AVERROR_UNKNOWN;
-    }
-
-    /* create a "slave" session with those same properties, to be used for
-     * actual scaling */
-    err = MFXInit(impl, &ver, &s->session);
-    if (err != MFX_ERR_NONE) {
-        av_log(ctx, AV_LOG_ERROR, "Error initializing a session for scaling\n");
-        return AVERROR_UNKNOWN;
-    }
-
-    if (handle) {
-        err = MFXVideoCORE_SetHandle(s->session, handle_type, handle);
-        if (err != MFX_ERR_NONE)
-            return AVERROR_UNKNOWN;
-    }
-
-    if (QSV_RUNTIME_VERSION_ATLEAST(ver, 1, 25)) {
-        err = MFXJoinSession(device_hwctx->session, s->session);
-            if (err != MFX_ERR_NONE)
-                return AVERROR_UNKNOWN;
-    }
-
-    memset(&par, 0, sizeof(par));
-
-    if (opaque) {
-        s->surface_ptrs_in = av_mallocz_array(in_frames_hwctx->nb_surfaces,
-                                              sizeof(*s->surface_ptrs_in));
-        if (!s->surface_ptrs_in)
-            return AVERROR(ENOMEM);
-        for (i = 0; i < in_frames_hwctx->nb_surfaces; i++)
-            s->surface_ptrs_in[i] = in_frames_hwctx->surfaces + i;
-        s->nb_surface_ptrs_in = in_frames_hwctx->nb_surfaces;
-
-        s->surface_ptrs_out = av_mallocz_array(out_frames_hwctx->nb_surfaces,
-                                               sizeof(*s->surface_ptrs_out));
-        if (!s->surface_ptrs_out)
-            return AVERROR(ENOMEM);
-        for (i = 0; i < out_frames_hwctx->nb_surfaces; i++)
-            s->surface_ptrs_out[i] = out_frames_hwctx->surfaces + i;
-        s->nb_surface_ptrs_out = out_frames_hwctx->nb_surfaces;
-
-        s->opaque_alloc.In.Surfaces   = s->surface_ptrs_in;
-        s->opaque_alloc.In.NumSurface = s->nb_surface_ptrs_in;
-        s->opaque_alloc.In.Type       = in_frames_hwctx->frame_type;
-
-        s->opaque_alloc.Out.Surfaces   = s->surface_ptrs_out;
-        s->opaque_alloc.Out.NumSurface = s->nb_surface_ptrs_out;
-        s->opaque_alloc.Out.Type       = out_frames_hwctx->frame_type;
-
-        s->opaque_alloc.Header.BufferId = MFX_EXTBUFF_OPAQUE_SURFACE_ALLOCATION;
-        s->opaque_alloc.Header.BufferSz = sizeof(s->opaque_alloc);
-
-        s->ext_buffers[s->num_ext_buf++] = (mfxExtBuffer*)&s->opaque_alloc;
-
-        par.IOPattern = MFX_IOPATTERN_IN_OPAQUE_MEMORY | MFX_IOPATTERN_OUT_OPAQUE_MEMORY;
-    } else {
-        mfxFrameAllocator frame_allocator = {
-            .pthis  = ctx,
-            .Alloc  = frame_alloc,
-            .Lock   = frame_lock,
-            .Unlock = frame_unlock,
-            .GetHDL = frame_get_hdl,
-            .Free   = frame_free,
-        };
-
-        s->mem_ids_in = av_mallocz_array(in_frames_hwctx->nb_surfaces,
-                                         sizeof(*s->mem_ids_in));
-        if (!s->mem_ids_in)
-            return AVERROR(ENOMEM);
-        for (i = 0; i < in_frames_hwctx->nb_surfaces; i++) {
-            s->mem_ids_in[i] = in_frames_hwctx->surfaces[i].Data.MemId;
-            in_frames_hwctx->surfaces[i].Info.CropW = in_width;
-            in_frames_hwctx->surfaces[i].Info.CropH = in_height;
-        }
-        s->nb_mem_ids_in = in_frames_hwctx->nb_surfaces;
-
-        s->mem_ids_out = av_mallocz_array(out_frames_hwctx->nb_surfaces,
-                                          sizeof(*s->mem_ids_out));
-        if (!s->mem_ids_out)
-            return AVERROR(ENOMEM);
-        for (i = 0; i < out_frames_hwctx->nb_surfaces; i++)
-            s->mem_ids_out[i] = out_frames_hwctx->surfaces[i].Data.MemId;
-        s->nb_mem_ids_out = out_frames_hwctx->nb_surfaces;
-
-        err = MFXVideoCORE_SetFrameAllocator(s->session, &frame_allocator);
-        if (err != MFX_ERR_NONE)
-            return AVERROR_UNKNOWN;
-
-        par.IOPattern = MFX_IOPATTERN_IN_VIDEO_MEMORY | MFX_IOPATTERN_OUT_VIDEO_MEMORY;
-    }
-
-#if QSV_HAVE_SCALING_CONFIG
-    memset(&s->scale_conf, 0, sizeof(mfxExtVPPScaling));
-    s->scale_conf.Header.BufferId     = MFX_EXTBUFF_VPP_SCALING;
-    s->scale_conf.Header.BufferSz     = sizeof(mfxExtVPPScaling);
-    s->scale_conf.ScalingMode         = s->mode;
-    s->ext_buffers[s->num_ext_buf++]  = (mfxExtBuffer*)&s->scale_conf;
-    av_log(ctx, AV_LOG_VERBOSE, "Scaling mode: %d\n", s->mode);
-#endif
-
-    par.ExtParam    = s->ext_buffers;
-    par.NumExtParam = s->num_ext_buf;
-
-    par.AsyncDepth = 1;    // TODO async
-
-    par.vpp.In  = in_frames_hwctx->surfaces[0].Info;
-    par.vpp.Out = out_frames_hwctx->surfaces[0].Info;
-
-    /* Apparently VPP requires the frame rate to be set to some value, otherwise
-     * init will fail (probably for the framerate conversion filter). Since we
-     * are only doing scaling here, we just invent an arbitrary
-     * value */
-    par.vpp.In.FrameRateExtN  = 25;
-    par.vpp.In.FrameRateExtD  = 1;
-    par.vpp.Out.FrameRateExtN = 25;
-    par.vpp.Out.FrameRateExtD = 1;
-
-    /* Print input memory mode */
-    ff_qsvvpp_print_iopattern(ctx, par.IOPattern & 0x0F, "VPP");
-    /* Print output memory mode */
-    ff_qsvvpp_print_iopattern(ctx, par.IOPattern & 0xF0, "VPP");
-    err = MFXVideoVPP_Init(s->session, &par);
-    if (err < 0)
-        return ff_qsvvpp_print_error(ctx, err,
-                                     "Error opening the VPP for scaling");
-    else if (err > 0) {
-        ff_qsvvpp_print_warning(ctx, err,
-                                "Warning in VPP initialization");
-        return AVERROR_UNKNOWN;
-    }
-
-    return 0;
-}
-
-static int init_scale_session(AVFilterContext *ctx, int in_width, int in_height,
-                              int out_width, int out_height)
-{
-    int ret;
-
-    qsvscale_uninit(ctx);
-
-    ret = init_out_pool(ctx, out_width, out_height);
-    if (ret < 0)
-        return ret;
-
-    ret = init_out_session(ctx, in_width, in_height);
-    if (ret < 0)
-        return ret;
-
-    return 0;
-}
-
-static int qsvscale_config_props(AVFilterLink *outlink)
-{
-    AVFilterContext *ctx = outlink->src;
-    AVFilterLink *inlink = outlink->src->inputs[0];
-    QSVScaleContext  *s = ctx->priv;
-    int64_t w, h;
-    double var_values[VARS_NB], res;
-    char *expr;
-    int ret;
-
-    var_values[VAR_PI]    = M_PI;
-    var_values[VAR_PHI]   = M_PHI;
-    var_values[VAR_E]     = M_E;
-    var_values[VAR_IN_W]  = var_values[VAR_IW] = inlink->w;
-    var_values[VAR_IN_H]  = var_values[VAR_IH] = inlink->h;
-    var_values[VAR_OUT_W] = var_values[VAR_OW] = NAN;
-    var_values[VAR_OUT_H] = var_values[VAR_OH] = NAN;
-    var_values[VAR_A]     = (double) inlink->w / inlink->h;
-    var_values[VAR_SAR]   = inlink->sample_aspect_ratio.num ?
-        (double) inlink->sample_aspect_ratio.num / inlink->sample_aspect_ratio.den : 1;
-    var_values[VAR_DAR]   = var_values[VAR_A] * var_values[VAR_SAR];
-
-    /* evaluate width and height */
-    av_expr_parse_and_eval(&res, (expr = s->w_expr),
-                           var_names, var_values,
-                           NULL, NULL, NULL, NULL, NULL, 0, ctx);
-    s->w = var_values[VAR_OUT_W] = var_values[VAR_OW] = res;
-    if ((ret = av_expr_parse_and_eval(&res, (expr = s->h_expr),
-                                      var_names, var_values,
-                                      NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0)
-        goto fail;
-    s->h = var_values[VAR_OUT_H] = var_values[VAR_OH] = res;
-    /* evaluate again the width, as it may depend on the output height */
-    if ((ret = av_expr_parse_and_eval(&res, (expr = s->w_expr),
-                                      var_names, var_values,
-                                      NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0)
-        goto fail;
-    s->w = res;
-
-    w = s->w;
-    h = s->h;
-
-    /* sanity check params */
-    if (w <  -1 || h <  -1) {
-        av_log(ctx, AV_LOG_ERROR, "Size values less than -1 are not acceptable.\n");
-        return AVERROR(EINVAL);
-    }
-    if (w == -1 && h == -1)
-        s->w = s->h = 0;
-
-    if (!(w = s->w))
-        w = inlink->w;
-    if (!(h = s->h))
-        h = inlink->h;
-    if (w == -1)
-        w = av_rescale(h, inlink->w, inlink->h);
-    if (h == -1)
-        h = av_rescale(w, inlink->h, inlink->w);
-
-    if (w > INT_MAX || h > INT_MAX ||
-        (h * inlink->w) > INT_MAX  ||
-        (w * inlink->h) > INT_MAX)
-        av_log(ctx, AV_LOG_ERROR, "Rescaled value for width or height is too big.\n");
-
-    outlink->w = w;
-    outlink->h = h;
-
-    ret = init_scale_session(ctx, inlink->w, inlink->h, w, h);
-    if (ret < 0)
-        return ret;
-
-    av_log(ctx, AV_LOG_VERBOSE, "w:%d h:%d -> w:%d h:%d\n",
-           inlink->w, inlink->h, outlink->w, outlink->h);
-
-    if (inlink->sample_aspect_ratio.num)
-        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w,
-                                                             outlink->w*inlink->h},
-                                                inlink->sample_aspect_ratio);
-    else
-        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
-
-    return 0;
-
-fail:
-    av_log(ctx, AV_LOG_ERROR,
-           "Error when evaluating the expression '%s'\n", expr);
-    return ret;
-}
-
-static int qsvscale_filter_frame(AVFilterLink *link, AVFrame *in)
-{
-    AVFilterContext             *ctx = link->dst;
-    QSVScaleContext               *s = ctx->priv;
-    AVFilterLink            *outlink = ctx->outputs[0];
-
-    mfxSyncPoint sync = NULL;
-    mfxStatus err;
-
-    AVFrame *out = NULL;
-    int ret = 0;
-
-    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
-    if (!out) {
-        ret = AVERROR(ENOMEM);
-        goto fail;
-    }
-
-    do {
-        err = MFXVideoVPP_RunFrameVPPAsync(s->session,
-                                           (mfxFrameSurface1*)in->data[3],
-                                           (mfxFrameSurface1*)out->data[3],
-                                           NULL, &sync);
-        if (err == MFX_WRN_DEVICE_BUSY)
-            av_usleep(1);
-    } while (err == MFX_WRN_DEVICE_BUSY);
-
-    if (err < 0) {
-        ret = ff_qsvvpp_print_error(ctx, err, "Error during scaling");
-        goto fail;
-    }
-
-    if (!sync) {
-        av_log(ctx, AV_LOG_ERROR, "No sync during scaling\n");
-        ret = AVERROR_UNKNOWN;
-        goto fail;
-    }
-
-    do {
-        err = MFXVideoCORE_SyncOperation(s->session, sync, 1000);
-    } while (err == MFX_WRN_IN_EXECUTION);
-    if (err < 0) {
-        ret = ff_qsvvpp_print_error(ctx, err, "Error synchronizing the operation");
-        goto fail;
-    }
-
-    ret = av_frame_copy_props(out, in);
-    if (ret < 0)
-        goto fail;
-
-    out->width  = outlink->w;
-    out->height = outlink->h;
-
-    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
-              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
-              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
-              INT_MAX);
-
-    av_frame_free(&in);
-    return ff_filter_frame(outlink, out);
-fail:
-    av_frame_free(&in);
-    av_frame_free(&out);
-    return ret;
-}
-
-#define OFFSET(x) offsetof(QSVScaleContext, x)
-#define FLAGS AV_OPT_FLAG_VIDEO_PARAM|AV_OPT_FLAG_FILTERING_PARAM
-static const AVOption options[] = {
-    { "w",      "Output video width",  OFFSET(w_expr),     AV_OPT_TYPE_STRING, { .str = "iw"   }, .flags = FLAGS },
-    { "h",      "Output video height", OFFSET(h_expr),     AV_OPT_TYPE_STRING, { .str = "ih"   }, .flags = FLAGS },
-    { "format", "Output pixel format", OFFSET(format_str), AV_OPT_TYPE_STRING, { .str = "same" }, .flags = FLAGS },
-
-#if QSV_HAVE_SCALING_CONFIG
-    { "mode",      "set scaling mode",    OFFSET(mode),    AV_OPT_TYPE_INT,    { .i64 = MFX_SCALING_MODE_DEFAULT}, MFX_SCALING_MODE_DEFAULT, MFX_SCALING_MODE_QUALITY, FLAGS, "mode"},
-    { "low_power", "low power mode",        0,             AV_OPT_TYPE_CONST,  { .i64 = MFX_SCALING_MODE_LOWPOWER}, INT_MIN, INT_MAX, FLAGS, "mode"},
-    { "hq",        "high quality mode",     0,             AV_OPT_TYPE_CONST,  { .i64 = MFX_SCALING_MODE_QUALITY},  INT_MIN, INT_MAX, FLAGS, "mode"},
-#else
-    { "mode",      "(not supported)",     OFFSET(mode),    AV_OPT_TYPE_INT,    { .i64 = 0}, 0, INT_MAX, FLAGS, "mode"},
-    { "low_power", "",                      0,             AV_OPT_TYPE_CONST,  { .i64 = 1}, 0,   0,     FLAGS, "mode"},
-    { "hq",        "",                      0,             AV_OPT_TYPE_CONST,  { .i64 = 2}, 0,   0,     FLAGS, "mode"},
-#endif
-
-    { NULL },
-};
-
-static const AVClass qsvscale_class = {
-    .class_name = "scale_qsv",
-    .item_name  = av_default_item_name,
-    .option     = options,
-    .version    = LIBAVUTIL_VERSION_INT,
-};
-
-static const AVFilterPad qsvscale_inputs[] = {
-    {
-        .name         = "default",
-        .type         = AVMEDIA_TYPE_VIDEO,
-        .filter_frame = qsvscale_filter_frame,
-    },
-    { NULL }
-};
-
-static const AVFilterPad qsvscale_outputs[] = {
-    {
-        .name         = "default",
-        .type         = AVMEDIA_TYPE_VIDEO,
-        .config_props = qsvscale_config_props,
-    },
-    { NULL }
-};
-
-AVFilter ff_vf_scale_qsv = {
-    .name      = "scale_qsv",
-    .description = NULL_IF_CONFIG_SMALL("QuickSync video scaling and format conversion"),
-
-    .init          = qsvscale_init,
-    .uninit        = qsvscale_uninit,
-    .query_formats = qsvscale_query_formats,
-
-    .priv_size = sizeof(QSVScaleContext),
-    .priv_class = &qsvscale_class,
-
-    .inputs    = qsvscale_inputs,
-    .outputs   = qsvscale_outputs,
-
-    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
-};
Index: jellyfin-ffmpeg/libavfilter/vf_vpp_qsv.c
===================================================================
--- libavfilter/vf_vpp_qsv.c
+++ libavfilter/vf_vpp_qsv.c
@@ -32,6 +32,7 @@
 #include "formats.h"
 #include "internal.h"
 #include "avfilter.h"
+#include "filters.h"
 #include "libavcodec/avcodec.h"
 #include "libavformat/avformat.h"
 
@@ -42,14 +43,13 @@
 #define FLAGS (AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_FILTERING_PARAM)
 
 /* number of video enhancement filters */
-#define ENH_FILTERS_COUNT (7)
-#define QSV_HAVE_ROTATION  QSV_VERSION_ATLEAST(1, 17)
-#define QSV_HAVE_MIRRORING QSV_VERSION_ATLEAST(1, 19)
+#define ENH_FILTERS_COUNT (8)
+#define QSV_HAVE_ROTATION       QSV_VERSION_ATLEAST(1, 17)
+#define QSV_HAVE_MIRRORING      QSV_VERSION_ATLEAST(1, 19)
+#define QSV_HAVE_SCALING_CONFIG QSV_VERSION_ATLEAST(1, 19)
 
 typedef struct VPPContext{
-    const AVClass *class;
-
-    QSVVPPContext *qsv;
+    QSVVPPContext qsv;
 
     /* Video Enhancement Algorithms */
     mfxExtVPPDeinterlacing  deinterlace_conf;
@@ -59,7 +59,15 @@ typedef struct VPPContext{
     mfxExtVPPProcAmp procamp_conf;
     mfxExtVPPRotation rotation_conf;
     mfxExtVPPMirroring mirroring_conf;
+#ifdef QSV_HAVE_SCALING_CONFIG
+    mfxExtVPPScaling scale_conf;
+#endif
 
+    /**
+     * New dimensions. Special values are:
+     *   0 = original width/height
+     *  -1 = keep original aspect
+     */
     int out_width;
     int out_height;
     /**
@@ -83,8 +91,10 @@ typedef struct VPPContext{
     int rotate;                 /* rotate angle : [0, 90, 180, 270] */
     int hflip;                  /* flip mode : 0 = off, 1 = HORIZONTAL flip */
 
+    int scale_mode;             /* scale mode : 0 = auto, 1 = low power, 2 = high quality */
+
     /* param for the procamp */
-    int    procamp;            /* enable procamp */
+    int    procamp;             /* enable procamp */
     float  hue;
     float  saturation;
     float  contrast;
@@ -93,44 +103,10 @@ typedef struct VPPContext{
     char *cx, *cy, *cw, *ch;
     char *ow, *oh;
     char *output_format_str;
-} VPPContext;
-
-static const AVOption options[] = {
-    { "deinterlace", "deinterlace mode: 0=off, 1=bob, 2=advanced", OFFSET(deinterlace), AV_OPT_TYPE_INT,      { .i64 = 0 }, 0, MFX_DEINTERLACING_ADVANCED, .flags = FLAGS, "deinterlace" },
-    { "bob",         "Bob deinterlace mode.",                      0,                   AV_OPT_TYPE_CONST,    { .i64 = MFX_DEINTERLACING_BOB },            .flags = FLAGS, "deinterlace" },
-    { "advanced",    "Advanced deinterlace mode. ",                0,                   AV_OPT_TYPE_CONST,    { .i64 = MFX_DEINTERLACING_ADVANCED },       .flags = FLAGS, "deinterlace" },
-
-    { "denoise",     "denoise level [0, 100]",       OFFSET(denoise),     AV_OPT_TYPE_INT,      { .i64 = 0 }, 0, 100, .flags = FLAGS },
-    { "detail",      "enhancement level [0, 100]",   OFFSET(detail),      AV_OPT_TYPE_INT,      { .i64 = 0 }, 0, 100, .flags = FLAGS },
-    { "framerate",   "output framerate",             OFFSET(framerate),   AV_OPT_TYPE_RATIONAL, { .dbl = 0.0 },0, DBL_MAX, .flags = FLAGS },
-    { "procamp",     "Enable ProcAmp",               OFFSET(procamp),     AV_OPT_TYPE_INT,      { .i64 = 0 }, 0, 1, .flags = FLAGS},
-    { "hue",         "ProcAmp hue",                  OFFSET(hue),         AV_OPT_TYPE_FLOAT,    { .dbl = 0.0 }, -180.0, 180.0, .flags = FLAGS},
-    { "saturation",  "ProcAmp saturation",           OFFSET(saturation),  AV_OPT_TYPE_FLOAT,    { .dbl = 1.0 }, 0.0, 10.0, .flags = FLAGS},
-    { "contrast",    "ProcAmp contrast",             OFFSET(contrast),    AV_OPT_TYPE_FLOAT,    { .dbl = 1.0 }, 0.0, 10.0, .flags = FLAGS},
-    { "brightness",  "ProcAmp brightness",           OFFSET(brightness),  AV_OPT_TYPE_FLOAT,    { .dbl = 0.0 }, -100.0, 100.0, .flags = FLAGS},
 
-    { "transpose",  "set transpose direction",       OFFSET(transpose),   AV_OPT_TYPE_INT,      { .i64 = -1 }, -1, 6, FLAGS, "transpose"},
-        { "cclock_hflip",  "rotate counter-clockwise with horizontal flip",  0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_CCLOCK_FLIP }, .flags=FLAGS, .unit = "transpose" },
-        { "clock",         "rotate clockwise",                               0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_CLOCK       }, .flags=FLAGS, .unit = "transpose" },
-        { "cclock",        "rotate counter-clockwise",                       0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_CCLOCK      }, .flags=FLAGS, .unit = "transpose" },
-        { "clock_hflip",   "rotate clockwise with horizontal flip",          0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_CLOCK_FLIP  }, .flags=FLAGS, .unit = "transpose" },
-        { "reversal",      "rotate by half-turn",                            0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_REVERSAL    }, .flags=FLAGS, .unit = "transpose" },
-        { "hflip",         "flip horizontally",                              0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_HFLIP       }, .flags=FLAGS, .unit = "transpose" },
-        { "vflip",         "flip vertically",                                0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_VFLIP       }, .flags=FLAGS, .unit = "transpose" },
-
-    { "cw",   "set the width crop area expression",   OFFSET(cw), AV_OPT_TYPE_STRING, { .str = "iw" }, 0, 0, FLAGS },
-    { "ch",   "set the height crop area expression",  OFFSET(ch), AV_OPT_TYPE_STRING, { .str = "ih" }, 0, 0, FLAGS },
-    { "cx",   "set the x crop area expression",       OFFSET(cx), AV_OPT_TYPE_STRING, { .str = "(in_w-out_w)/2" }, 0, 0, FLAGS },
-    { "cy",   "set the y crop area expression",       OFFSET(cy), AV_OPT_TYPE_STRING, { .str = "(in_h-out_h)/2" }, 0, 0, FLAGS },
-
-    { "w",      "Output video width",  OFFSET(ow), AV_OPT_TYPE_STRING, { .str="cw" }, 0, 255, .flags = FLAGS },
-    { "width",  "Output video width",  OFFSET(ow), AV_OPT_TYPE_STRING, { .str="cw" }, 0, 255, .flags = FLAGS },
-    { "h",      "Output video height", OFFSET(oh), AV_OPT_TYPE_STRING, { .str="w*ch/cw" }, 0, 255, .flags = FLAGS },
-    { "height", "Output video height", OFFSET(oh), AV_OPT_TYPE_STRING, { .str="w*ch/cw" }, 0, 255, .flags = FLAGS },
-    { "format", "Output pixel format", OFFSET(output_format_str), AV_OPT_TYPE_STRING, { .str = "same" }, .flags = FLAGS },
-
-    { NULL }
-};
+    int has_passthrough;        /* apply pass through mode if possible */
+    int field_rate;             /* deinterlace mode */
+} VPPContext;
 
 static const char *const var_names[] = {
     "iw", "in_w",
@@ -141,32 +117,41 @@ static const char *const var_names[] = {
     "ch",
     "cx",
     "cy",
+    "a", "dar",
+    "sar",
     NULL
 };
 
 enum var_name {
-    VAR_iW, VAR_IN_W,
-    VAR_iH, VAR_IN_H,
-    VAR_oW, VAR_OUT_W, VAR_W,
-    VAR_oH, VAR_OUT_H, VAR_H,
+    VAR_IW, VAR_IN_W,
+    VAR_IH, VAR_IN_H,
+    VAR_OW, VAR_OUT_W, VAR_W,
+    VAR_OH, VAR_OUT_H, VAR_H,
     CW,
     CH,
     CX,
     CY,
+    VAR_A, VAR_DAR,
+    VAR_SAR,
     VAR_VARS_NB
 };
 
 static int eval_expr(AVFilterContext *ctx)
 {
 #define PASS_EXPR(e, s) {\
-    ret = av_expr_parse(&e, s, var_names, NULL, NULL, NULL, NULL, 0, ctx); \
-    if (ret < 0) {\
-        av_log(ctx, AV_LOG_ERROR, "Error when passing '%s'.\n", s);\
-        goto release;\
+    if (s) {\
+        ret = av_expr_parse(&e, s, var_names, NULL, NULL, NULL, NULL, 0, ctx); \
+        if (ret < 0) {                                                  \
+            av_log(ctx, AV_LOG_ERROR, "Error when passing '%s'.\n", s); \
+            goto release;                                               \
+        }                                                               \
     }\
 }
-#define CALC_EXPR(e, v, i) {\
-    i = v = av_expr_eval(e, var_values, NULL); \
+#define CALC_EXPR(e, v, i, d) {\
+    if (e)\
+        i = v = av_expr_eval(e, var_values, NULL);      \
+    else\
+        i = v = d;\
 }
     VPPContext *vpp = ctx->priv;
     double  var_values[VAR_VARS_NB] = { NAN };
@@ -184,39 +169,43 @@ static int eval_expr(AVFilterContext *ct
     PASS_EXPR(cx_expr, vpp->cx);
     PASS_EXPR(cy_expr, vpp->cy);
 
-    var_values[VAR_iW] =
+    var_values[VAR_IW] =
     var_values[VAR_IN_W] = ctx->inputs[0]->w;
 
-    var_values[VAR_iH] =
+    var_values[VAR_IH] =
     var_values[VAR_IN_H] = ctx->inputs[0]->h;
 
+    var_values[VAR_A] = (double)var_values[VAR_IN_W] / var_values[VAR_IN_H];
+    var_values[VAR_SAR] = ctx->inputs[0]->sample_aspect_ratio.num ?
+        (double)ctx->inputs[0]->sample_aspect_ratio.num / ctx->inputs[0]->sample_aspect_ratio.den : 1;
+    var_values[VAR_DAR] = var_values[VAR_A] * var_values[VAR_SAR];
+
     /* crop params */
-    CALC_EXPR(cw_expr, var_values[CW], vpp->crop_w);
-    CALC_EXPR(ch_expr, var_values[CH], vpp->crop_h);
+    CALC_EXPR(cw_expr, var_values[CW], vpp->crop_w, var_values[VAR_IW]);
+    CALC_EXPR(ch_expr, var_values[CH], vpp->crop_h, var_values[VAR_IH]);
 
     /* calc again in case cw is relative to ch */
-    CALC_EXPR(cw_expr, var_values[CW], vpp->crop_w);
+    CALC_EXPR(cw_expr, var_values[CW], vpp->crop_w, var_values[VAR_IW]);
 
     CALC_EXPR(w_expr,
-            var_values[VAR_OUT_W] = var_values[VAR_oW] = var_values[VAR_W],
-            vpp->out_width);
+            var_values[VAR_OUT_W] = var_values[VAR_OW] = var_values[VAR_W],
+            vpp->out_width, var_values[CW]);
     CALC_EXPR(h_expr,
-            var_values[VAR_OUT_H] = var_values[VAR_oH] = var_values[VAR_H],
-            vpp->out_height);
+            var_values[VAR_OUT_H] = var_values[VAR_OH] = var_values[VAR_H],
+            vpp->out_height, var_values[CH]);
 
     /* calc again in case ow is relative to oh */
     CALC_EXPR(w_expr,
-            var_values[VAR_OUT_W] = var_values[VAR_oW] = var_values[VAR_W],
-            vpp->out_width);
+            var_values[VAR_OUT_W] = var_values[VAR_OW] = var_values[VAR_W],
+            vpp->out_width, var_values[CW]);
 
-
-    CALC_EXPR(cx_expr, var_values[CX], vpp->crop_x);
-    CALC_EXPR(cy_expr, var_values[CY], vpp->crop_y);
+    CALC_EXPR(cx_expr, var_values[CX], vpp->crop_x, (var_values[VAR_IW] - var_values[VAR_OW]) / 2);
+    CALC_EXPR(cy_expr, var_values[CY], vpp->crop_y, (var_values[VAR_IH] - var_values[VAR_OH]) / 2);
 
     /* calc again in case cx is relative to cy */
-    CALC_EXPR(cx_expr, var_values[CX], vpp->crop_x);
+    CALC_EXPR(cx_expr, var_values[CX], vpp->crop_x, (var_values[VAR_IW] - var_values[VAR_OW]) / 2);
 
-    if ((vpp->crop_w != var_values[VAR_iW]) || (vpp->crop_h != var_values[VAR_iH]))
+    if ((vpp->crop_w != var_values[VAR_IW]) || (vpp->crop_h != var_values[VAR_IH]))
         vpp->use_crop = 1;
 
 release:
@@ -232,11 +221,25 @@ release:
     return ret;
 }
 
+static av_cold int vpp_preinit(AVFilterContext *ctx)
+{
+    VPPContext  *vpp  = ctx->priv;
+    /* For AV_OPT_TYPE_STRING options, NULL is handled in other way so
+     * we needn't set default value here
+     */
+    vpp->saturation = 1.0;
+    vpp->contrast = 1.0;
+    vpp->transpose = -1;
+    vpp->field_rate = 1;
+
+    return 0;
+}
+
 static av_cold int vpp_init(AVFilterContext *ctx)
 {
     VPPContext  *vpp  = ctx->priv;
 
-    if (!strcmp(vpp->output_format_str, "same")) {
+    if (!vpp->output_format_str || !strcmp(vpp->output_format_str, "same")) {
         vpp->out_format = AV_PIX_FMT_NONE;
     } else {
         vpp->out_format = av_get_pix_fmt(vpp->output_format_str);
@@ -254,11 +257,15 @@ static int config_input(AVFilterLink *in
     AVFilterContext *ctx = inlink->dst;
     VPPContext      *vpp = ctx->priv;
     int              ret;
+    int64_t          ow, oh;
 
     if (vpp->framerate.den == 0 || vpp->framerate.num == 0)
         vpp->framerate = inlink->frame_rate;
 
-    if (av_cmp_q(vpp->framerate, inlink->frame_rate))
+    if (vpp->field_rate == 2)
+        vpp->framerate = av_mul_q(inlink->frame_rate,
+                                  (AVRational){ 2, 1 });
+    else if (av_cmp_q(vpp->framerate, inlink->frame_rate))
         vpp->use_frc = 1;
 
     ret = eval_expr(ctx);
@@ -267,11 +274,38 @@ static int config_input(AVFilterLink *in
         return ret;
     }
 
-    if (vpp->out_height == 0 || vpp->out_width == 0) {
-        vpp->out_width  = inlink->w;
-        vpp->out_height = inlink->h;
+    ow = vpp->out_width;
+    oh = vpp->out_height;
+
+    /* sanity check params */
+    if (ow <  -1 || oh <  -1) {
+        av_log(ctx, AV_LOG_ERROR, "Size values less than -1 are not acceptable.\n");
+        return AVERROR(EINVAL);
     }
 
+    if (ow == -1 && oh == -1)
+        vpp->out_width = vpp->out_height = 0;
+
+    if (!(ow = vpp->out_width))
+        ow = inlink->w;
+
+    if (!(oh = vpp->out_height))
+        oh = inlink->h;
+
+    if (ow == -1)
+        ow = av_rescale(oh, inlink->w, inlink->h);
+
+    if (oh == -1)
+        oh = av_rescale(ow, inlink->h, inlink->w);
+
+    if (ow > INT_MAX || oh > INT_MAX ||
+        (oh * inlink->w) > INT_MAX  ||
+        (ow * inlink->h) > INT_MAX)
+        av_log(ctx, AV_LOG_ERROR, "Rescaled value for width or height is too big.\n");
+
+    vpp->out_width = ow;
+    vpp->out_height = oh;
+
     if (vpp->use_crop) {
         vpp->crop_x = FFMAX(vpp->crop_x, 0);
         vpp->crop_y = FFMAX(vpp->crop_y, 0);
@@ -298,7 +332,7 @@ static int config_output(AVFilterLink *o
     outlink->w          = vpp->out_width;
     outlink->h          = vpp->out_height;
     outlink->frame_rate = vpp->framerate;
-    outlink->time_base  = av_inv_q(vpp->framerate);
+    outlink->time_base  = inlink->time_base;
 
     param.filter_frame  = NULL;
     param.num_ext_buf   = 0;
@@ -327,53 +361,46 @@ static int config_output(AVFilterLink *o
         param.crop     = &crop;
     }
 
-    if (vpp->deinterlace) {
-        memset(&vpp->deinterlace_conf, 0, sizeof(mfxExtVPPDeinterlacing));
-        vpp->deinterlace_conf.Header.BufferId = MFX_EXTBUFF_VPP_DEINTERLACING;
-        vpp->deinterlace_conf.Header.BufferSz = sizeof(mfxExtVPPDeinterlacing);
-        vpp->deinterlace_conf.Mode = vpp->deinterlace == 1 ?
-                                     MFX_DEINTERLACING_BOB : MFX_DEINTERLACING_ADVANCED;
+#define INIT_MFX_EXTBUF(extbuf, id) do { \
+        memset(&vpp->extbuf, 0, sizeof(vpp->extbuf)); \
+        vpp->extbuf.Header.BufferId = id; \
+        vpp->extbuf.Header.BufferSz = sizeof(vpp->extbuf); \
+        param.ext_buf[param.num_ext_buf++] = (mfxExtBuffer*)&vpp->extbuf; \
+    } while (0)
+
+#define SET_MFX_PARAM_FIELD(extbuf, field, value) do { \
+        vpp->extbuf.field = value; \
+    } while (0)
 
-        param.ext_buf[param.num_ext_buf++] = (mfxExtBuffer*)&vpp->deinterlace_conf;
+    vpp->qsv.deinterlace_enabled = !!vpp->deinterlace;
+
+    if (vpp->deinterlace) {
+        INIT_MFX_EXTBUF(deinterlace_conf, MFX_EXTBUFF_VPP_DEINTERLACING);
+        SET_MFX_PARAM_FIELD(deinterlace_conf, Mode, (vpp->deinterlace == 1 ?
+                            MFX_DEINTERLACING_BOB : MFX_DEINTERLACING_ADVANCED));
     }
 
     if (vpp->use_frc) {
-        memset(&vpp->frc_conf, 0, sizeof(mfxExtVPPFrameRateConversion));
-        vpp->frc_conf.Header.BufferId = MFX_EXTBUFF_VPP_FRAME_RATE_CONVERSION;
-        vpp->frc_conf.Header.BufferSz = sizeof(mfxExtVPPFrameRateConversion);
-        vpp->frc_conf.Algorithm = MFX_FRCALGM_DISTRIBUTED_TIMESTAMP;
-
-        param.ext_buf[param.num_ext_buf++] = (mfxExtBuffer*)&vpp->frc_conf;
+        INIT_MFX_EXTBUF(frc_conf, MFX_EXTBUFF_VPP_FRAME_RATE_CONVERSION);
+        SET_MFX_PARAM_FIELD(frc_conf, Algorithm, MFX_FRCALGM_DISTRIBUTED_TIMESTAMP);
     }
 
     if (vpp->denoise) {
-        memset(&vpp->denoise_conf, 0, sizeof(mfxExtVPPDenoise));
-        vpp->denoise_conf.Header.BufferId = MFX_EXTBUFF_VPP_DENOISE;
-        vpp->denoise_conf.Header.BufferSz = sizeof(mfxExtVPPDenoise);
-        vpp->denoise_conf.DenoiseFactor   = vpp->denoise;
-
-        param.ext_buf[param.num_ext_buf++] = (mfxExtBuffer*)&vpp->denoise_conf;
+        INIT_MFX_EXTBUF(denoise_conf, MFX_EXTBUFF_VPP_DENOISE);
+        SET_MFX_PARAM_FIELD(denoise_conf, DenoiseFactor, vpp->denoise);
     }
 
     if (vpp->detail) {
-        memset(&vpp->detail_conf, 0, sizeof(mfxExtVPPDetail));
-        vpp->detail_conf.Header.BufferId  = MFX_EXTBUFF_VPP_DETAIL;
-        vpp->detail_conf.Header.BufferSz  = sizeof(mfxExtVPPDetail);
-        vpp->detail_conf.DetailFactor = vpp->detail;
-
-        param.ext_buf[param.num_ext_buf++] = (mfxExtBuffer*)&vpp->detail_conf;
+        INIT_MFX_EXTBUF(detail_conf, MFX_EXTBUFF_VPP_DETAIL);
+        SET_MFX_PARAM_FIELD(detail_conf, DetailFactor, vpp->detail);
     }
 
     if (vpp->procamp) {
-        memset(&vpp->procamp_conf, 0, sizeof(mfxExtVPPProcAmp));
-        vpp->procamp_conf.Header.BufferId  = MFX_EXTBUFF_VPP_PROCAMP;
-        vpp->procamp_conf.Header.BufferSz  = sizeof(mfxExtVPPProcAmp);
-        vpp->procamp_conf.Hue              = vpp->hue;
-        vpp->procamp_conf.Saturation       = vpp->saturation;
-        vpp->procamp_conf.Contrast         = vpp->contrast;
-        vpp->procamp_conf.Brightness       = vpp->brightness;
-
-        param.ext_buf[param.num_ext_buf++] = (mfxExtBuffer*)&vpp->procamp_conf;
+        INIT_MFX_EXTBUF(procamp_conf, MFX_EXTBUFF_VPP_PROCAMP);
+        SET_MFX_PARAM_FIELD(procamp_conf, Hue, vpp->hue);
+        SET_MFX_PARAM_FIELD(procamp_conf, Saturation, vpp->saturation);
+        SET_MFX_PARAM_FIELD(procamp_conf, Contrast, vpp->contrast);
+        SET_MFX_PARAM_FIELD(procamp_conf, Brightness, vpp->brightness);
     }
 
     if (vpp->transpose >= 0) {
@@ -420,18 +447,14 @@ static int config_output(AVFilterLink *o
 
     if (vpp->rotate) {
 #ifdef QSV_HAVE_ROTATION
-        memset(&vpp->rotation_conf, 0, sizeof(mfxExtVPPRotation));
-        vpp->rotation_conf.Header.BufferId  = MFX_EXTBUFF_VPP_ROTATION;
-        vpp->rotation_conf.Header.BufferSz  = sizeof(mfxExtVPPRotation);
-        vpp->rotation_conf.Angle = vpp->rotate;
+        INIT_MFX_EXTBUF(rotation_conf, MFX_EXTBUFF_VPP_ROTATION);
+        SET_MFX_PARAM_FIELD(rotation_conf, Angle, vpp->rotate);
 
         if (MFX_ANGLE_90 == vpp->rotate || MFX_ANGLE_270 == vpp->rotate) {
             FFSWAP(int, vpp->out_width, vpp->out_height);
             FFSWAP(int, outlink->w, outlink->h);
             av_log(ctx, AV_LOG_DEBUG, "Swap width and height for clock/cclock rotation.\n");
         }
-
-        param.ext_buf[param.num_ext_buf++] = (mfxExtBuffer*)&vpp->rotation_conf;
 #else
         av_log(ctx, AV_LOG_WARNING, "The QSV VPP rotate option is "
             "not supported with this MSDK version.\n");
@@ -441,12 +464,8 @@ static int config_output(AVFilterLink *o
 
     if (vpp->hflip) {
 #ifdef QSV_HAVE_MIRRORING
-        memset(&vpp->mirroring_conf, 0, sizeof(mfxExtVPPMirroring));
-        vpp->mirroring_conf.Header.BufferId = MFX_EXTBUFF_VPP_MIRRORING;
-        vpp->mirroring_conf.Header.BufferSz = sizeof(mfxExtVPPMirroring);
-        vpp->mirroring_conf.Type = vpp->hflip;
-
-        param.ext_buf[param.num_ext_buf++] = (mfxExtBuffer*)&vpp->mirroring_conf;
+        INIT_MFX_EXTBUF(mirroring_conf, MFX_EXTBUFF_VPP_MIRRORING);
+        SET_MFX_PARAM_FIELD(mirroring_conf, Type, vpp->hflip);
 #else
         av_log(ctx, AV_LOG_WARNING, "The QSV VPP hflip option is "
             "not supported with this MSDK version.\n");
@@ -454,11 +473,26 @@ static int config_output(AVFilterLink *o
 #endif
     }
 
+    if (inlink->w != outlink->w || inlink->h != outlink->h) {
+#ifdef QSV_HAVE_SCALING_CONFIG
+        INIT_MFX_EXTBUF(scale_conf, MFX_EXTBUFF_VPP_SCALING);
+        SET_MFX_PARAM_FIELD(scale_conf, ScalingMode, vpp->scale_mode);
+#else
+        av_log(ctx, AV_LOG_WARNING, "The QSV VPP Scale option is "
+            "not supported with this MSDK version.\n");
+#endif
+    }
+
+#undef INIT_MFX_EXTBUF
+#undef SET_MFX_PARAM_FIELD
+
     if (vpp->use_frc || vpp->use_crop || vpp->deinterlace || vpp->denoise ||
         vpp->detail || vpp->procamp || vpp->rotate || vpp->hflip ||
-        inlink->w != outlink->w || inlink->h != outlink->h || in_format != vpp->out_format)
-        return ff_qsvvpp_create(ctx, &vpp->qsv, &param);
+        inlink->w != outlink->w || inlink->h != outlink->h || in_format != vpp->out_format ||
+        !vpp->has_passthrough)
+        return ff_qsvvpp_init(ctx, &param);
     else {
+        /* No MFX session is created in this case */
         av_log(ctx, AV_LOG_VERBOSE, "qsv vpp pass through mode.\n");
         if (inlink->hw_frames_ctx)
             outlink->hw_frames_ctx = av_buffer_ref(inlink->hw_frames_ctx);
@@ -467,26 +501,161 @@ static int config_output(AVFilterLink *o
     return 0;
 }
 
-static int filter_frame(AVFilterLink *inlink, AVFrame *picref)
+static int activate(AVFilterContext *ctx)
 {
-    int              ret = 0;
-    AVFilterContext  *ctx = inlink->dst;
-    VPPContext       *vpp = inlink->dst->priv;
-    AVFilterLink     *outlink = ctx->outputs[0];
-
-    if (vpp->qsv) {
-        ret = ff_qsvvpp_filter_frame(vpp->qsv, inlink, picref);
-        av_frame_free(&picref);
+    AVFilterLink *inlink = ctx->inputs[0];
+    AVFilterLink *outlink = ctx->outputs[0];
+    QSVVPPContext *qsv = ctx->priv;
+    AVFrame *in = NULL;
+    int ret, status = 0;
+    int64_t pts = AV_NOPTS_VALUE;
+
+    FF_FILTER_FORWARD_STATUS_BACK(outlink, inlink);
+
+    if (!qsv->eof) {
+        ret = ff_inlink_consume_frame(inlink, &in);
+        if (ret < 0)
+            return ret;
+
+        if (ff_inlink_acknowledge_status(inlink, &status, &pts)) {
+            if (status == AVERROR_EOF) {
+                qsv->eof = 1;
+            }
+        }
+    }
+
+    if (qsv->session) {
+        if (in || qsv->eof) {
+            ret = ff_qsvvpp_filter_frame(qsv, inlink, in);
+            av_frame_free(&in);
+
+            if (qsv->eof) {
+                ff_outlink_set_status(outlink, status, pts);
+                return 0;
+            }
+
+            if (qsv->got_frame) {
+                qsv->got_frame = 0;
+                return ret;
+            }
+        }
     } else {
-        if (picref->pts != AV_NOPTS_VALUE)
-            picref->pts = av_rescale_q(picref->pts, inlink->time_base, outlink->time_base);
-        ret = ff_filter_frame(outlink, picref);
+        /* No MFX session is created in pass-through mode */
+        if (in) {
+            if (in->pts != AV_NOPTS_VALUE)
+                in->pts = av_rescale_q(in->pts, inlink->time_base, outlink->time_base);
+
+            ret = ff_filter_frame(outlink, in);
+            return ret;
+        }
     }
 
-    return ret;
+    if (qsv->eof) {
+        ff_outlink_set_status(outlink, status, pts);
+        return 0;
+    } else {
+        FF_FILTER_FORWARD_WANTED(outlink, inlink);
+    }
+
+    return FFERROR_NOT_READY;
 }
 
-static int query_formats(AVFilterContext *ctx)
+static av_cold void vpp_uninit(AVFilterContext *ctx)
+{
+    ff_qsvvpp_close(ctx);
+}
+
+static const AVFilterPad vpp_inputs[] = {
+    {
+        .name          = "default",
+        .type          = AVMEDIA_TYPE_VIDEO,
+        .config_props  = config_input,
+    },
+    { NULL }
+};
+
+static const AVFilterPad vpp_outputs[] = {
+    {
+        .name          = "default",
+        .type          = AVMEDIA_TYPE_VIDEO,
+        .config_props  = config_output,
+    },
+    { NULL }
+};
+
+#define DEFINE_QSV_FILTER(x, sn, ln) \
+static const AVClass x##_class = { \
+    .class_name = #sn "_qsv", \
+    .item_name  = av_default_item_name, \
+    .option     = x##_options, \
+    .version    = LIBAVUTIL_VERSION_INT, \
+}; \
+const AVFilter ff_vf_##sn##_qsv = { \
+    .name           = #sn "_qsv", \
+    .description    = NULL_IF_CONFIG_SMALL("Quick Sync Video " #ln), \
+    .preinit        = x##_preinit, \
+    .init           = vpp_init, \
+    .uninit         = vpp_uninit, \
+    .priv_size      = sizeof(VPPContext), \
+    .priv_class     = &x##_class, \
+    .inputs         = vpp_inputs, \
+    .outputs        = vpp_outputs, \
+    .query_formats  = x##_query_formats, \
+    .activate       = activate, \
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE, \
+};
+
+static const AVOption vpp_options[] = {
+    { "deinterlace", "deinterlace mode: 0=off, 1=bob, 2=advanced", OFFSET(deinterlace), AV_OPT_TYPE_INT,      { .i64 = 0 }, 0, MFX_DEINTERLACING_ADVANCED, .flags = FLAGS, "deinterlace" },
+    { "bob",         "Bob deinterlace mode.",                      0,                   AV_OPT_TYPE_CONST,    { .i64 = MFX_DEINTERLACING_BOB },            .flags = FLAGS, "deinterlace" },
+    { "advanced",    "Advanced deinterlace mode. ",                0,                   AV_OPT_TYPE_CONST,    { .i64 = MFX_DEINTERLACING_ADVANCED },       .flags = FLAGS, "deinterlace" },
+
+    { "denoise",     "denoise level [0, 100]",       OFFSET(denoise),     AV_OPT_TYPE_INT,      { .i64 = 0 }, 0, 100, .flags = FLAGS },
+    { "detail",      "enhancement level [0, 100]",   OFFSET(detail),      AV_OPT_TYPE_INT,      { .i64 = 0 }, 0, 100, .flags = FLAGS },
+    { "framerate",   "output framerate",             OFFSET(framerate),   AV_OPT_TYPE_RATIONAL, { .dbl = 0.0 },0, DBL_MAX, .flags = FLAGS },
+    { "procamp",     "Enable ProcAmp",               OFFSET(procamp),     AV_OPT_TYPE_INT,      { .i64 = 0 }, 0, 1, .flags = FLAGS},
+    { "hue",         "ProcAmp hue",                  OFFSET(hue),         AV_OPT_TYPE_FLOAT,    { .dbl = 0.0 }, -180.0, 180.0, .flags = FLAGS},
+    { "saturation",  "ProcAmp saturation",           OFFSET(saturation),  AV_OPT_TYPE_FLOAT,    { .dbl = 1.0 }, 0.0, 10.0, .flags = FLAGS},
+    { "contrast",    "ProcAmp contrast",             OFFSET(contrast),    AV_OPT_TYPE_FLOAT,    { .dbl = 1.0 }, 0.0, 10.0, .flags = FLAGS},
+    { "brightness",  "ProcAmp brightness",           OFFSET(brightness),  AV_OPT_TYPE_FLOAT,    { .dbl = 0.0 }, -100.0, 100.0, .flags = FLAGS},
+
+    { "transpose",  "set transpose direction",       OFFSET(transpose),   AV_OPT_TYPE_INT,      { .i64 = -1 }, -1, 6, FLAGS, "transpose"},
+        { "cclock_hflip",  "rotate counter-clockwise with horizontal flip",  0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_CCLOCK_FLIP }, .flags=FLAGS, .unit = "transpose" },
+        { "clock",         "rotate clockwise",                               0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_CLOCK       }, .flags=FLAGS, .unit = "transpose" },
+        { "cclock",        "rotate counter-clockwise",                       0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_CCLOCK      }, .flags=FLAGS, .unit = "transpose" },
+        { "clock_hflip",   "rotate clockwise with horizontal flip",          0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_CLOCK_FLIP  }, .flags=FLAGS, .unit = "transpose" },
+        { "reversal",      "rotate by half-turn",                            0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_REVERSAL    }, .flags=FLAGS, .unit = "transpose" },
+        { "hflip",         "flip horizontally",                              0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_HFLIP       }, .flags=FLAGS, .unit = "transpose" },
+        { "vflip",         "flip vertically",                                0, AV_OPT_TYPE_CONST, { .i64 = TRANSPOSE_VFLIP       }, .flags=FLAGS, .unit = "transpose" },
+
+    { "cw",   "set the width crop area expression",   OFFSET(cw), AV_OPT_TYPE_STRING, { .str = "iw" }, 0, 0, FLAGS },
+    { "ch",   "set the height crop area expression",  OFFSET(ch), AV_OPT_TYPE_STRING, { .str = "ih" }, 0, 0, FLAGS },
+    { "cx",   "set the x crop area expression",       OFFSET(cx), AV_OPT_TYPE_STRING, { .str = "(in_w-out_w)/2" }, 0, 0, FLAGS },
+    { "cy",   "set the y crop area expression",       OFFSET(cy), AV_OPT_TYPE_STRING, { .str = "(in_h-out_h)/2" }, 0, 0, FLAGS },
+
+    { "w",      "Output video width(0=input video width, -1=keep input video aspect)",  OFFSET(ow), AV_OPT_TYPE_STRING, { .str="cw" }, 0, 255, .flags = FLAGS },
+    { "width",  "Output video width(0=input video width, -1=keep input video aspect)",  OFFSET(ow), AV_OPT_TYPE_STRING, { .str="cw" }, 0, 255, .flags = FLAGS },
+    { "h",      "Output video height(0=input video height, -1=keep input video aspect)", OFFSET(oh), AV_OPT_TYPE_STRING, { .str="w*ch/cw" }, 0, 255, .flags = FLAGS },
+    { "height", "Output video height(0=input video height, -1=keep input video aspect)", OFFSET(oh), AV_OPT_TYPE_STRING, { .str="w*ch/cw" }, 0, 255, .flags = FLAGS },
+    { "format", "Output pixel format", OFFSET(output_format_str), AV_OPT_TYPE_STRING, { .str = "same" }, .flags = FLAGS },
+    { "async_depth", "Internal parallelization depth, the higher the value the higher the latency.", OFFSET(qsv.async_depth), AV_OPT_TYPE_INT, { .i64 = 4 }, 0, INT_MAX, .flags = FLAGS },
+#if QSV_HAVE_SCALING_CONFIG
+    { "scale_mode", "scale mode", OFFSET(scale_mode), AV_OPT_TYPE_INT, { .i64 = MFX_SCALING_MODE_DEFAULT }, MFX_SCALING_MODE_DEFAULT, MFX_SCALING_MODE_QUALITY, .flags = FLAGS, "scale mode" },
+    { "auto",      "auto mode",             0,    AV_OPT_TYPE_CONST,  { .i64 = MFX_SCALING_MODE_DEFAULT},  INT_MIN, INT_MAX, FLAGS, "scale mode"},
+    { "low_power", "low power mode",        0,    AV_OPT_TYPE_CONST,  { .i64 = MFX_SCALING_MODE_LOWPOWER}, INT_MIN, INT_MAX, FLAGS, "scale mode"},
+    { "hq",        "high quality mode",     0,    AV_OPT_TYPE_CONST,  { .i64 = MFX_SCALING_MODE_QUALITY},  INT_MIN, INT_MAX, FLAGS, "scale mode"},
+#else
+    { "scale_mode", "(not supported)",        OFFSET(scale_mode), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS, "scale mode" },
+    { "auto",      "",                      0,    AV_OPT_TYPE_CONST,  { .i64 = 0}, 0,   0,     FLAGS, "scale mode"},
+    { "low_power", "",                      0,    AV_OPT_TYPE_CONST,  { .i64 = 1}, 0,   0,     FLAGS, "scale mode"},
+    { "hq",        "",                      0,    AV_OPT_TYPE_CONST,  { .i64 = 2}, 0,   0,     FLAGS, "scale mode"},
+#endif
+    { "passthrough", "Apply pass through mode if possible.", OFFSET(has_passthrough), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, .flags = FLAGS },
+
+    { NULL }
+};
+
+static int vpp_query_formats(AVFilterContext *ctx)
 {
     int ret;
     static const enum AVPixelFormat in_pix_fmts[] = {
@@ -512,48 +681,92 @@ static int query_formats(AVFilterContext
                           &ctx->outputs[0]->incfg.formats);
 }
 
-static av_cold void vpp_uninit(AVFilterContext *ctx)
+DEFINE_QSV_FILTER(vpp, vpp, VPP);
+
+static int default_query_formats(AVFilterContext *ctx)
 {
-    VPPContext *vpp = ctx->priv;
+    static const enum AVPixelFormat pixel_formats[] = {
+        AV_PIX_FMT_QSV, AV_PIX_FMT_NONE,
+    };
+    AVFilterFormats *pix_fmts  = ff_make_format_list(pixel_formats);
+    int ret;
+
+    if ((ret = ff_set_common_formats(ctx, pix_fmts)) < 0)
+        return ret;
 
-    ff_qsvvpp_free(&vpp->qsv);
+    return 0;
 }
 
-static const AVClass vpp_class = {
-    .class_name = "vpp_qsv",
-    .item_name  = av_default_item_name,
-    .option     = options,
-    .version    = LIBAVUTIL_VERSION_INT,
-};
+static av_cold int default_preinit(AVFilterContext *ctx)
+{
+    VPPContext  *vpp  = ctx->priv;
 
-static const AVFilterPad vpp_inputs[] = {
-    {
-        .name          = "default",
-        .type          = AVMEDIA_TYPE_VIDEO,
-        .config_props  = config_input,
-        .filter_frame  = filter_frame,
-    },
-    { NULL }
-};
+    vpp_preinit(ctx);
+    vpp->has_passthrough = 0;
 
-static const AVFilterPad vpp_outputs[] = {
-    {
-        .name          = "default",
-        .type          = AVMEDIA_TYPE_VIDEO,
-        .config_props  = config_output,
-    },
-    { NULL }
+    return 0;
+}
+
+static const AVOption qsvscale_options[] = {
+    { "w",      "Output video width(0=input video width, -1=keep input video aspect)",  OFFSET(ow), AV_OPT_TYPE_STRING, { .str = "iw"   }, .flags = FLAGS },
+    { "h",      "Output video height(0=input video height, -1=keep input video aspect)", OFFSET(oh), AV_OPT_TYPE_STRING, { .str = "ih"   }, .flags = FLAGS },
+    { "cw",     "set the width crop area expression",   OFFSET(cw), AV_OPT_TYPE_STRING, { .str = "iw" }, .flags = FLAGS },
+    { "ch",     "set the height crop area expression",  OFFSET(ch), AV_OPT_TYPE_STRING, { .str = "ih" }, .flags = FLAGS },
+    { "cx",     "set the x crop area expression",       OFFSET(cx), AV_OPT_TYPE_STRING, { .str = "(iw-ow)/2" }, .flags = FLAGS },
+    { "cy",     "set the y crop area expression",       OFFSET(cy), AV_OPT_TYPE_STRING, { .str = "(ih-oh)/2" }, .flags = FLAGS },
+    { "format", "Output pixel format", OFFSET(output_format_str), AV_OPT_TYPE_STRING, { .str = "same" }, .flags = FLAGS },
+
+#if QSV_HAVE_SCALING_CONFIG
+    { "mode",      "set scaling mode",    OFFSET(scale_mode),    AV_OPT_TYPE_INT,    { .i64 = MFX_SCALING_MODE_DEFAULT}, MFX_SCALING_MODE_DEFAULT, MFX_SCALING_MODE_QUALITY, FLAGS, "mode"},
+    { "low_power", "low power mode",        0,             AV_OPT_TYPE_CONST,  { .i64 = MFX_SCALING_MODE_LOWPOWER}, INT_MIN, INT_MAX, FLAGS, "mode"},
+    { "hq",        "high quality mode",     0,             AV_OPT_TYPE_CONST,  { .i64 = MFX_SCALING_MODE_QUALITY},  INT_MIN, INT_MAX, FLAGS, "mode"},
+#else
+    { "mode",      "(not supported)",     OFFSET(scale_mode),    AV_OPT_TYPE_INT,    { .i64 = 0}, 0, INT_MAX, FLAGS, "mode"},
+    { "low_power", "",                      0,             AV_OPT_TYPE_CONST,  { .i64 = 1}, 0,   0,     FLAGS, "mode"},
+    { "hq",        "",                      0,             AV_OPT_TYPE_CONST,  { .i64 = 2}, 0,   0,     FLAGS, "mode"},
+#endif
+
+    { "async_depth", "Internal parallelization depth, the higher the value the higher the latency.", OFFSET(qsv.async_depth), AV_OPT_TYPE_INT, { .i64 = 4 }, 0, INT_MAX, .flags = FLAGS },
+
+    { NULL },
 };
 
-AVFilter ff_vf_vpp_qsv = {
-    .name          = "vpp_qsv",
-    .description   = NULL_IF_CONFIG_SMALL("Quick Sync Video VPP."),
-    .priv_size     = sizeof(VPPContext),
-    .query_formats = query_formats,
-    .init          = vpp_init,
-    .uninit        = vpp_uninit,
-    .inputs        = vpp_inputs,
-    .outputs       = vpp_outputs,
-    .priv_class    = &vpp_class,
-    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+static int qsvscale_query_formats(AVFilterContext *ctx)
+{
+    return default_query_formats(ctx);
+}
+
+static av_cold int qsvscale_preinit(AVFilterContext *ctx)
+{
+    return default_preinit(ctx);
+}
+
+DEFINE_QSV_FILTER(qsvscale, scale, scaling and format conversion);
+
+static const AVOption qsvdeint_options[] = {
+    { "mode", "set deinterlace mode", OFFSET(deinterlace),   AV_OPT_TYPE_INT, {.i64 = MFX_DEINTERLACING_ADVANCED}, MFX_DEINTERLACING_BOB, MFX_DEINTERLACING_ADVANCED, FLAGS, "mode"},
+    { "bob",   "bob algorithm",                  0, AV_OPT_TYPE_CONST,      {.i64 = MFX_DEINTERLACING_BOB}, MFX_DEINTERLACING_BOB, MFX_DEINTERLACING_ADVANCED, FLAGS, "mode"},
+    { "advanced", "Motion adaptive algorithm",   0, AV_OPT_TYPE_CONST, {.i64 = MFX_DEINTERLACING_ADVANCED}, MFX_DEINTERLACING_BOB, MFX_DEINTERLACING_ADVANCED, FLAGS, "mode"},
+
+    { "rate", "Generate output at frame rate or field rate",
+      OFFSET(field_rate), AV_OPT_TYPE_INT, { .i64 = 2 }, 1, 2, FLAGS, "rate" },
+    { "frame", "Output at frame rate (one frame of output for each field-pair)",
+      0, AV_OPT_TYPE_CONST, { .i64 = 1 }, 0, 0, FLAGS, "rate" },
+    { "field", "Output at field rate (one frame of output for each field)",
+      0, AV_OPT_TYPE_CONST, { .i64 = 2 }, 0, 0, FLAGS, "rate" },
+
+    { "async_depth", "Internal parallelization depth, the higher the value the higher the latency.", OFFSET(qsv.async_depth), AV_OPT_TYPE_INT, { .i64 = 4 }, 0, INT_MAX, .flags = FLAGS },
+    { NULL },
 };
+
+static int qsvdeint_query_formats(AVFilterContext *ctx)
+{
+    return default_query_formats(ctx);
+}
+
+static av_cold int qsvdeint_preinit(AVFilterContext *ctx)
+{
+    return default_preinit(ctx);
+}
+
+DEFINE_QSV_FILTER(qsvdeint, deinterlace, deinterlacing);
Index: jellyfin-ffmpeg/libavutil/frame.c
===================================================================
--- libavutil/frame.c
+++ libavutil/frame.c
@@ -347,6 +347,36 @@ int av_frame_get_buffer(AVFrame *frame,
     return AVERROR(EINVAL);
 }
 
+int av_frame_copy_side_data(AVFrame* dst, const AVFrame* src, int flags)
+{
+    for (unsigned i = 0; i < src->nb_side_data; i++) {
+        const AVFrameSideData *sd_src = src->side_data[i];
+        AVFrameSideData *sd_dst;
+        if (   sd_src->type == AV_FRAME_DATA_PANSCAN
+            && (src->width != dst->width || src->height != dst->height))
+            continue;
+        if (flags & AV_FRAME_COPY_PROPS_FORCECOPY) {
+            sd_dst = av_frame_new_side_data(dst, sd_src->type,
+                                            sd_src->size);
+            if (!sd_dst) {
+                wipe_side_data(dst);
+                return AVERROR(ENOMEM);
+            }
+            memcpy(sd_dst->data, sd_src->data, sd_src->size);
+        } else {
+            AVBufferRef *ref = av_buffer_ref(sd_src->buf);
+            sd_dst = av_frame_new_side_data_from_buf(dst, sd_src->type, ref);
+            if (!sd_dst) {
+                av_buffer_unref(&ref);
+                wipe_side_data(dst);
+                return AVERROR(ENOMEM);
+            }
+        }
+        av_dict_copy(&sd_dst->metadata, sd_src->metadata, 0);
+    }
+    return 0;
+}
+
 static int frame_copy_props(AVFrame *dst, const AVFrame *src, int force_copy)
 {
     int ret, i;
@@ -395,31 +425,9 @@ FF_DISABLE_DEPRECATION_WARNINGS
 FF_ENABLE_DEPRECATION_WARNINGS
 #endif
 
-    for (i = 0; i < src->nb_side_data; i++) {
-        const AVFrameSideData *sd_src = src->side_data[i];
-        AVFrameSideData *sd_dst;
-        if (   sd_src->type == AV_FRAME_DATA_PANSCAN
-            && (src->width != dst->width || src->height != dst->height))
-            continue;
-        if (force_copy) {
-            sd_dst = av_frame_new_side_data(dst, sd_src->type,
-                                            sd_src->size);
-            if (!sd_dst) {
-                wipe_side_data(dst);
-                return AVERROR(ENOMEM);
-            }
-            memcpy(sd_dst->data, sd_src->data, sd_src->size);
-        } else {
-            AVBufferRef *ref = av_buffer_ref(sd_src->buf);
-            sd_dst = av_frame_new_side_data_from_buf(dst, sd_src->type, ref);
-            if (!sd_dst) {
-                av_buffer_unref(&ref);
-                wipe_side_data(dst);
-                return AVERROR(ENOMEM);
-            }
-        }
-        av_dict_copy(&sd_dst->metadata, sd_src->metadata, 0);
-    }
+    if (ret = av_frame_copy_side_data(dst, src,
+        force_copy ? AV_FRAME_COPY_PROPS_FORCECOPY : 0) < 0)
+        return ret;
 
 #if FF_API_FRAME_QP
 FF_DISABLE_DEPRECATION_WARNINGS
@@ -823,6 +831,17 @@ void av_frame_remove_side_data(AVFrame *
     }
 }
 
+void av_frame_remove_all_side_data(AVFrame *frame)
+{
+    int i;
+
+    for (i = frame->nb_side_data - 1; i >= 0; i--) {
+        free_side_data(&frame->side_data[i]);
+        frame->side_data[i] = frame->side_data[frame->nb_side_data - 1];
+        frame->nb_side_data--;
+    }
+}
+
 const char *av_frame_side_data_name(enum AVFrameSideDataType type)
 {
     switch(type) {
Index: jellyfin-ffmpeg/libavutil/frame.h
===================================================================
--- libavutil/frame.h
+++ libavutil/frame.h
@@ -897,6 +897,22 @@ int av_frame_copy(AVFrame *dst, const AV
 int av_frame_copy_props(AVFrame *dst, const AVFrame *src);
 
 /**
+ * Copy actual data buffers instead of references.
+ */
+#define AV_FRAME_COPY_PROPS_FORCECOPY  1
+
+/**
+ * Copy only side-data from src to dst.
+ *
+ * @param dst a frame to which the side data should be copied.
+ * @param src a frame from which to copy the side data.
+ * @param flags flags of type AV_FRAME_COPY_PROPS_*, controlling copy behavior.
+ *
+ * @return >= 0 on success, a negative AVERROR on error.
+ */
+int av_frame_copy_side_data(AVFrame* dst, const AVFrame* src, int flags);
+
+/**
  * Get the buffer reference a given data plane is stored in.
  *
  * @param plane index of the data plane of interest in frame->extended_data.
@@ -951,6 +967,10 @@ AVFrameSideData *av_frame_get_side_data(
  */
 void av_frame_remove_side_data(AVFrame *frame, enum AVFrameSideDataType type);
 
+/**
+ * Remove and free all side data in this frame.
+ */
+void av_frame_remove_all_side_data(AVFrame *frame);
 
 /**
  * Flags for frame cropping.
