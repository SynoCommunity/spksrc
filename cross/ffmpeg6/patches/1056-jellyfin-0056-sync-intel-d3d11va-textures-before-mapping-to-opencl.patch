Index: jellyfin-ffmpeg/libavcodec/dxva2.c
===================================================================
--- libavcodec/dxva2.c
+++ libavcodec/dxva2.c
@@ -714,8 +714,10 @@ int ff_dxva2_common_frame_params(AVCodec
 #if CONFIG_D3D11VA
     if (frames_ctx->format == AV_PIX_FMT_D3D11) {
         AVD3D11VAFramesContext *frames_hwctx = frames_ctx->hwctx;
+        AVD3D11VADeviceContext *device_hwctx = device_ctx->hwctx;
 
         frames_hwctx->BindFlags |= D3D11_BIND_DECODER;
+        frames_hwctx->require_sync = device_hwctx->device_desc.VendorId == 0x8086;
     }
 #endif
 
Index: jellyfin-ffmpeg/libavfilter/qsvvpp.c
===================================================================
--- libavfilter/qsvvpp.c
+++ libavfilter/qsvvpp.c
@@ -598,6 +598,9 @@ static int init_vpp_session(AVFilterCont
             out_frames_ctx->initial_pool_size += avctx->extra_hw_frames;
         out_frames_hwctx->frame_type      = s->out_mem_mode;
 
+        if (in_frames_hwctx)
+            out_frames_hwctx->require_sync = in_frames_hwctx->require_sync;
+
         ret = av_hwframe_ctx_init(out_frames_ref);
         if (ret < 0) {
             av_buffer_unref(&out_frames_ref);
Index: jellyfin-ffmpeg/libavutil/hwcontext_d3d11va.h
===================================================================
--- libavutil/hwcontext_d3d11va.h
+++ libavutil/hwcontext_d3d11va.h
@@ -183,6 +183,11 @@ typedef struct AVD3D11VAFramesContext {
      * This field is ignored/invalid if a user-allocated texture is provided.
     */
     AVD3D11FrameDescriptor *texture_infos;
+
+    /**
+     * Whether the frames require extra sync when exporting as external memory.
+     */
+    int require_sync;
 } AVD3D11VAFramesContext;
 
 #endif /* AVUTIL_HWCONTEXT_D3D11VA_H */
Index: jellyfin-ffmpeg/libavutil/hwcontext_opencl.c
===================================================================
--- libavutil/hwcontext_opencl.c
+++ libavutil/hwcontext_opencl.c
@@ -167,6 +167,10 @@ typedef struct OpenCLFramesContext {
     int                   nb_mapped_frames;
     AVOpenCLFrameDescriptor *mapped_frames;
 #endif
+#if HAVE_OPENCL_D3D11
+    ID3D11Asynchronous      *sync_point;
+    ID3D11Texture2D         *sync_tex_2x2;
+#endif
 } OpenCLFramesContext;
 
 static void CL_CALLBACK opencl_error_callback(const char *errinfo,
@@ -1788,7 +1792,12 @@ static void opencl_frames_uninit(AVHWFra
         av_freep(&priv->mapped_frames);
     }
 #endif
-
+#if HAVE_OPENCL_D3D11
+    if (priv->sync_point)
+        ID3D11Asynchronous_Release(priv->sync_point);
+    if (priv->sync_tex_2x2)
+        ID3D11Texture2D_Release(priv->sync_tex_2x2);
+#endif
     if (priv->command_queue) {
         cle = clReleaseCommandQueue(priv->command_queue);
         if (cle != CL_SUCCESS) {
@@ -2563,6 +2572,82 @@ fail:
 
 #if HAVE_OPENCL_D3D11
 
+static int opencl_init_d3d11_sync_point(OpenCLFramesContext    *priv,
+                                        AVD3D11VADeviceContext *device_hwctx,
+                                        ID3D11Texture2D        *src_texture,
+                                        void                   *logctx)
+{
+    HRESULT hr;
+    D3D11_QUERY_DESC query = { D3D11_QUERY_EVENT, 0 };
+    D3D11_TEXTURE2D_DESC src_desc = { 0 };
+    D3D11_TEXTURE2D_DESC dst_desc = {
+        .Width          = 2,
+        .Height         = 2,
+        .MipLevels      = 1,
+        .SampleDesc     = { .Count = 1 },
+        .ArraySize      = 1,
+        .Usage          = D3D11_USAGE_DEFAULT,
+    };
+
+    if (!priv || !device_hwctx || !src_texture)
+        return AVERROR(EINVAL);
+
+    hr = ID3D11Device_CreateQuery(device_hwctx->device, &query,
+                                  (ID3D11Query **)&priv->sync_point);
+    if (FAILED(hr)) {
+        av_log(logctx, AV_LOG_ERROR, "Could not create the sync point (%lx)\n", (long)hr);
+        goto fail;
+    }
+
+    ID3D11Texture2D_GetDesc(src_texture, &src_desc);
+    dst_desc.Format = src_desc.Format;
+    hr = ID3D11Device_CreateTexture2D(device_hwctx->device,
+                                      &dst_desc, NULL, &priv->sync_tex_2x2);
+    if (FAILED(hr)) {
+        av_log(logctx, AV_LOG_ERROR, "Could not create the sync texture (%lx)\n", (long)hr);
+        goto fail;
+    }
+
+    return 0;
+fail:
+    if (priv->sync_point)
+        ID3D11Asynchronous_Release(priv->sync_point);
+    if (priv->sync_tex_2x2)
+        ID3D11Texture2D_Release(priv->sync_tex_2x2);
+    return AVERROR_UNKNOWN;
+}
+
+static void opencl_sync_d3d11_texture(OpenCLFramesContext    *priv,
+                                      AVD3D11VADeviceContext *device_hwctx,
+                                      ID3D11Texture2D        *texture,
+                                      unsigned                subresource,
+                                      void                   *logctx)
+{
+    const D3D11_BOX box_2x2 = { 0, 0, 0, 2, 2, 1 };
+    BOOL data = FALSE;
+
+    if (!priv || !device_hwctx || !texture)
+        return;
+
+    av_log(logctx, AV_LOG_DEBUG, "Sync D3D11 texture %d\n", subresource);
+
+    device_hwctx->lock(device_hwctx->lock_ctx);
+    ID3D11DeviceContext_Begin(device_hwctx->device_context, priv->sync_point);
+
+    /* Force DX to wait for DXVA DEC/VP by copying 2x2 pixels, which can act as a sync point */
+    ID3D11DeviceContext_CopySubresourceRegion(device_hwctx->device_context,
+                                              (ID3D11Resource *)priv->sync_tex_2x2, 0, 0, 0, 0,
+                                              (ID3D11Resource *)texture, subresource, &box_2x2);
+    ID3D11DeviceContext_Flush(device_hwctx->device_context);
+    ID3D11DeviceContext_End(device_hwctx->device_context, priv->sync_point);
+
+    while ((S_OK != ID3D11DeviceContext_GetData(device_hwctx->device_context,
+                                                priv->sync_point,
+                                                &data,
+                                                sizeof(data), 0)) || (data != TRUE)) { /* do nothing */ }
+    device_hwctx->unlock(device_hwctx->lock_ctx);
+}
+
 #if CONFIG_LIBMFX
 
 static void opencl_unmap_from_d3d11_qsv(AVHWFramesContext *dst_fc,
@@ -2603,6 +2688,13 @@ static void opencl_unmap_from_d3d11_qsv(
 static int opencl_map_from_d3d11_qsv(AVHWFramesContext *dst_fc, AVFrame *dst,
                                      const AVFrame *src, int flags)
 {
+    AVHWFramesContext *src_fc =
+        (AVHWFramesContext*)src->hw_frames_ctx->data;
+    AVHWDeviceContext *src_dev = src_fc->device_ctx;
+    AVHWDeviceContext *src_subdev =
+        (AVHWDeviceContext*)src_dev->internal->source_device->data;
+    AVD3D11VADeviceContext *device_hwctx = src_subdev->hwctx;
+    AVQSVFramesContext     *src_hwctx = src_fc->hwctx;
     AVOpenCLDeviceContext    *dst_dev = dst_fc->device_ctx->hwctx;
     OpenCLDeviceContext  *device_priv = dst_fc->device_ctx->internal->priv;
     OpenCLFramesContext  *frames_priv = dst_fc->internal->priv;
@@ -2630,6 +2722,14 @@ static int opencl_map_from_d3d11_qsv(AVH
         return AVERROR(EINVAL);
     }
 
+    if (src_hwctx->require_sync &&
+        frames_priv->sync_point && frames_priv->sync_tex_2x2) {
+        opencl_sync_d3d11_texture(frames_priv,
+                                  device_hwctx,
+                                  tex, (decoder_target ? index : 0),
+                                  dst_fc);
+    }
+
     if (decoder_target) {
         desc = &frames_priv->mapped_frames[index];
     } else {
@@ -2701,6 +2801,10 @@ fail2:
 static int opencl_frames_derive_from_d3d11_qsv(AVHWFramesContext *dst_fc,
                                                AVHWFramesContext *src_fc, int flags)
 {
+    AVHWDeviceContext *src_dev = src_fc->device_ctx;
+    AVHWDeviceContext *src_subdev =
+        (AVHWDeviceContext*)src_dev->internal->source_device->data;
+    AVD3D11VADeviceContext *device_hwctx = src_subdev->hwctx;
     AVOpenCLDeviceContext    *dst_dev = dst_fc->device_ctx->hwctx;
     AVQSVFramesContext     *src_hwctx = src_fc->hwctx;
     OpenCLDeviceContext  *device_priv = dst_fc->device_ctx->internal->priv;
@@ -2709,8 +2813,8 @@ static int opencl_frames_derive_from_d3d
     cl_int cle;
     int err, i, p, nb_planes = 2;
 
-    mfxHDLPair *pair = (mfxHDLPair*)src_hwctx->surfaces[i].Data.MemId;
-    ID3D11Texture2D *tex = (ID3D11Texture2D*)pair->first;
+    mfxHDLPair *pair = (mfxHDLPair *)src_hwctx->surfaces[0].Data.MemId;
+    ID3D11Texture2D *tex = (ID3D11Texture2D *)pair->first;
 
     if (src_fc->sw_format != AV_PIX_FMT_NV12 &&
         src_fc->sw_format != AV_PIX_FMT_P010) {
@@ -2725,6 +2829,14 @@ static int opencl_frames_derive_from_d3d
         return AVERROR(EINVAL);
     }
 
+    if (src_hwctx->require_sync) {
+        err = opencl_init_d3d11_sync_point(frames_priv,
+                                           device_hwctx,
+                                           tex, dst_fc);
+        if (err < 0)
+            return err;
+    }
+
     if (!(src_hwctx->frame_type & MFX_MEMTYPE_VIDEO_MEMORY_DECODER_TARGET) ||
         (src_hwctx->frame_type & MFX_MEMTYPE_VIDEO_MEMORY_PROCESSOR_TARGET) ||
         (src_hwctx->frame_type & MFX_MEMTYPE_FROM_VPPOUT)) {
@@ -2748,6 +2860,8 @@ static int opencl_frames_derive_from_d3d
     for (i = 0; i < frames_priv->nb_mapped_frames; i++) {
         AVOpenCLFrameDescriptor *desc = &frames_priv->mapped_frames[i];
         desc->nb_planes = nb_planes;
+        pair = (mfxHDLPair *)src_hwctx->surfaces[i].Data.MemId;
+        tex = (ID3D11Texture2D *)pair->first;
 
         for (p = 0; p < nb_planes; p++) {
             UINT subresource = 2 * i + p;
@@ -2816,6 +2930,10 @@ static void opencl_unmap_from_d3d11(AVHW
 static int opencl_map_from_d3d11(AVHWFramesContext *dst_fc, AVFrame *dst,
                                  const AVFrame *src, int flags)
 {
+    AVHWFramesContext *src_fc =
+        (AVHWFramesContext*)src->hw_frames_ctx->data;
+    AVD3D11VAFramesContext *src_hwctx = src_fc->hwctx;
+    AVD3D11VADeviceContext *device_hwctx = src_fc->device_ctx->hwctx;
     OpenCLDeviceContext  *device_priv = dst_fc->device_ctx->internal->priv;
     OpenCLFramesContext  *frames_priv = dst_fc->internal->priv;
     AVOpenCLFrameDescriptor *desc;
@@ -2846,6 +2964,14 @@ static int opencl_map_from_d3d11(AVHWFra
     mem_objs = device_priv->d3d11_map_amd ? &desc->planes[nb_planes]
                                           : desc->planes;
 
+    if (src_hwctx->require_sync &&
+        frames_priv->sync_point && frames_priv->sync_tex_2x2) {
+        opencl_sync_d3d11_texture(frames_priv,
+                                  device_hwctx,
+                                  src->data[0], index,
+                                  dst_fc);
+    }
+
     cle = device_priv->clEnqueueAcquireD3D11ObjectsKHR(
         frames_priv->command_queue, num_objs, mem_objs,
         0, NULL, &event);
@@ -2885,6 +3011,7 @@ fail:
 static int opencl_frames_derive_from_d3d11(AVHWFramesContext *dst_fc,
                                            AVHWFramesContext *src_fc, int flags)
 {
+    AVD3D11VADeviceContext *device_hwctx = src_fc->device_ctx->hwctx;
     AVOpenCLDeviceContext    *dst_dev = dst_fc->device_ctx->hwctx;
     AVD3D11VAFramesContext *src_hwctx = src_fc->hwctx;
     OpenCLDeviceContext  *device_priv = dst_fc->device_ctx->internal->priv;
@@ -2928,6 +3055,14 @@ static int opencl_frames_derive_from_d3d
     if (!frames_priv->mapped_frames)
         return AVERROR(ENOMEM);
 
+    if (src_hwctx->require_sync) {
+        err = opencl_init_d3d11_sync_point(frames_priv,
+                                           device_hwctx,
+                                           src_hwctx->texture, dst_fc);
+        if (err < 0)
+            return err;
+    }
+
     for (i = 0; i < frames_priv->nb_mapped_frames; i++) {
         AVOpenCLFrameDescriptor *desc = &frames_priv->mapped_frames[i];
         desc->nb_planes = nb_planes;
Index: jellyfin-ffmpeg/libavutil/hwcontext_qsv.c
===================================================================
--- libavutil/hwcontext_qsv.c
+++ libavutil/hwcontext_qsv.c
@@ -1868,6 +1868,7 @@ static int qsv_frames_derive_to(AVHWFram
             } else {
                 dst_hwctx->frame_type |= MFX_MEMTYPE_VIDEO_MEMORY_DECODER_TARGET;
             }
+            dst_hwctx->require_sync = src_hwctx->require_sync;
         }
         break;
 #endif
Index: jellyfin-ffmpeg/libavutil/hwcontext_qsv.h
===================================================================
--- libavutil/hwcontext_qsv.h
+++ libavutil/hwcontext_qsv.h
@@ -64,6 +64,11 @@ typedef struct AVQSVFramesContext {
      * A combination of MFX_MEMTYPE_* describing the frame pool.
      */
     int frame_type;
+
+    /**
+     * Whether the frames require extra sync when exporting as external memory.
+     */
+    int require_sync;
 } AVQSVFramesContext;
 
 #endif /* AVUTIL_HWCONTEXT_QSV_H */
