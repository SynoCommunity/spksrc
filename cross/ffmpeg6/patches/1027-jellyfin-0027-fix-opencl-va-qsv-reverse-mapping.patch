Index: jellyfin-ffmpeg/libavcodec/qsv.c
===================================================================
--- libavcodec/qsv.c
+++ libavcodec/qsv.c
@@ -834,7 +834,7 @@ static mfxStatus qsv_frame_alloc(mfxHDL
         AVHWFramesContext *frames_ctx = (AVHWFramesContext*)ctx->hw_frames_ctx->data;
         AVQSVFramesContext *frames_hwctx = frames_ctx->hwctx;
         mfxFrameInfo      *i  = &req->Info;
-        mfxFrameInfo      *i1 = &frames_hwctx->surfaces[0].Info;
+        mfxFrameInfo      *i1 = &frames_hwctx->reserve_surface.Info;
 
         if (i->Width  > i1->Width  || i->Height > i1->Height ||
             i->FourCC != i1->FourCC || i->ChromaFormat != i1->ChromaFormat) {
@@ -949,7 +949,7 @@ static mfxStatus qsv_frame_lock(mfxHDL p
     if (!qsv_mid->hw_frame->hw_frames_ctx)
         goto fail;
 
-    qsv_mid->surf.Info = hw_frames_hwctx->surfaces[0].Info;
+    qsv_mid->surf.Info = hw_frames_hwctx->reserve_surface.Info;
     qsv_mid->surf.Data.MemId = qsv_mid->handle_pair;
 
     /* map the data to the system memory */
Index: jellyfin-ffmpeg/libavcodec/qsvenc.c
===================================================================
--- libavcodec/qsvenc.c
+++ libavcodec/qsvenc.c
@@ -721,8 +721,8 @@ static int init_video_param_jpeg(AVCodec
     if (avctx->hw_frames_ctx) {
         AVHWFramesContext *frames_ctx    = (AVHWFramesContext *)avctx->hw_frames_ctx->data;
         AVQSVFramesContext *frames_hwctx = frames_ctx->hwctx;
-        q->param.mfx.FrameInfo.Width  = frames_hwctx->surfaces[0].Info.Width;
-        q->param.mfx.FrameInfo.Height = frames_hwctx->surfaces[0].Info.Height;
+        q->param.mfx.FrameInfo.Width  = frames_hwctx->reserve_surface.Info.Width;
+        q->param.mfx.FrameInfo.Height = frames_hwctx->reserve_surface.Info.Height;
     }
 
     if (avctx->framerate.den > 0 && avctx->framerate.num > 0) {
@@ -845,8 +845,8 @@ static int init_video_param(AVCodecConte
     if (avctx->hw_frames_ctx) {
         AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;
         AVQSVFramesContext *frames_hwctx = frames_ctx->hwctx;
-        q->param.mfx.FrameInfo.Width  = frames_hwctx->surfaces[0].Info.Width;
-        q->param.mfx.FrameInfo.Height = frames_hwctx->surfaces[0].Info.Height;
+        q->param.mfx.FrameInfo.Width  = frames_hwctx->reserve_surface.Info.Width;
+        q->param.mfx.FrameInfo.Height = frames_hwctx->reserve_surface.Info.Height;
     }
 
     if (avctx->framerate.den > 0 && avctx->framerate.num > 0) {
Index: jellyfin-ffmpeg/libavfilter/qsvvpp.c
===================================================================
--- libavfilter/qsvvpp.c
+++ libavfilter/qsvvpp.c
@@ -307,7 +307,7 @@ static int fill_frameinfo_by_link(mfxFra
 
         frames_ctx   = (AVHWFramesContext *)link->hw_frames_ctx->data;
         frames_hwctx = frames_ctx->hwctx;
-        *frameinfo   = frames_hwctx->surfaces[0].Info;
+        *frameinfo   = frames_hwctx->reserve_surface.Info;
     } else {
         pix_fmt = link->format;
         desc = av_pix_fmt_desc_get(pix_fmt);
Index: jellyfin-ffmpeg/libavutil/hwcontext_qsv.c
===================================================================
--- libavutil/hwcontext_qsv.c
+++ libavutil/hwcontext_qsv.c
@@ -611,7 +611,7 @@ static mfxStatus frame_alloc(mfxHDL pthi
     QSVFramesContext       *s = ctx->internal->priv;
     AVQSVFramesContext *hwctx = ctx->hwctx;
     mfxFrameInfo *i  = &req->Info;
-    mfxFrameInfo *i1 = &hwctx->surfaces[0].Info;
+    mfxFrameInfo *i1 = &hwctx->reserve_surface.Info;
 
     if (!(req->Type & MFX_MEMTYPE_VIDEO_MEMORY_PROCESSOR_TARGET) ||
         !(req->Type & (MFX_MEMTYPE_FROM_VPPIN | MFX_MEMTYPE_FROM_VPPOUT)) ||
@@ -1159,7 +1159,7 @@ static int qsv_init_internal_session(AVH
                               MFX_IOPATTERN_OUT_SYSTEM_MEMORY;
     par.AsyncDepth = 1;
 
-    par.vpp.In = frames_hwctx->surfaces[0].Info;
+    par.vpp.In = frames_hwctx->reserve_surface.Info;
 
     /* Apparently VPP requires the frame rate to be set to some value, otherwise
      * init will fail (probably for the framerate conversion filter). Since we
@@ -1248,6 +1248,14 @@ static int qsv_frames_init(AVHWFramesCon
     }
 #endif
 
+    ret = qsv_init_surface(ctx, &frames_hwctx->reserve_surface);
+    if (ret < 0) {
+#if QSV_HAVE_OPAQUE
+        av_freep(&s->surface_ptrs);
+#endif
+        return ret;
+    }
+
     s->session_download = NULL;
     s->session_upload   = NULL;
 
@@ -1776,13 +1784,7 @@ static int qsv_frames_derive_to(AVHWFram
 {
     QSVFramesContext *s = dst_ctx->internal->priv;
     AVQSVFramesContext *dst_hwctx = dst_ctx->hwctx;
-    int i;
-
-    if (src_ctx->initial_pool_size == 0) {
-        av_log(dst_ctx, AV_LOG_ERROR, "Only fixed-size pools can be "
-            "mapped to QSV frames.\n");
-        return AVERROR(EINVAL);
-    }
+    int i, ret;
 
     switch (src_ctx->device_ctx->type) {
 #if CONFIG_VAAPI
@@ -1798,11 +1800,20 @@ static int qsv_frames_derive_to(AVHWFram
             if (!s->surfaces_internal)
                 return AVERROR(ENOMEM);
             for (i = 0; i < src_hwctx->nb_surfaces; i++) {
-                qsv_init_surface(dst_ctx, &s->surfaces_internal[i]);
+                ret = qsv_init_surface(dst_ctx, &s->surfaces_internal[i]);
+                if (ret < 0) {
+                    av_freep(&s->surfaces_internal);
+                    return ret;
+                }
                 s->handle_pairs_internal[i].first = src_hwctx->surface_ids + i;
                 s->handle_pairs_internal[i].second = (mfxMemId)MFX_INFINITE;
                 s->surfaces_internal[i].Data.MemId = (mfxMemId)&s->handle_pairs_internal[i];
             }
+            ret = qsv_init_surface(dst_ctx, &dst_hwctx->reserve_surface);
+            if (ret < 0) {
+                av_freep(&s->surfaces_internal);
+                return ret;
+            }
             dst_hwctx->nb_surfaces = src_hwctx->nb_surfaces;
             dst_hwctx->frame_type  = MFX_MEMTYPE_VIDEO_MEMORY_DECODER_TARGET;
         }
@@ -1821,7 +1832,11 @@ static int qsv_frames_derive_to(AVHWFram
             if (!s->surfaces_internal)
                 return AVERROR(ENOMEM);
             for (i = 0; i < src_ctx->initial_pool_size; i++) {
-                qsv_init_surface(dst_ctx, &s->surfaces_internal[i]);
+                ret = qsv_init_surface(dst_ctx, &s->surfaces_internal[i]);
+                if (ret < 0) {
+                    av_freep(&s->surfaces_internal);
+                    return ret;
+                }
                 s->handle_pairs_internal[i].first = (mfxMemId)src_hwctx->texture_infos[i].texture;
                 if (src_hwctx->BindFlags & D3D11_BIND_RENDER_TARGET) {
                     s->handle_pairs_internal[i].second = (mfxMemId)MFX_INFINITE;
@@ -1830,6 +1845,11 @@ static int qsv_frames_derive_to(AVHWFram
                 }
                 s->surfaces_internal[i].Data.MemId = (mfxMemId)&s->handle_pairs_internal[i];
             }
+            ret = qsv_init_surface(dst_ctx, &dst_hwctx->reserve_surface);
+            if (ret < 0) {
+                av_freep(&s->surfaces_internal);
+                return ret;
+            }
             dst_hwctx->nb_surfaces = src_ctx->initial_pool_size;
             if (src_hwctx->BindFlags & D3D11_BIND_RENDER_TARGET) {
                 dst_hwctx->frame_type |= MFX_MEMTYPE_VIDEO_MEMORY_PROCESSOR_TARGET;
@@ -1852,11 +1872,20 @@ static int qsv_frames_derive_to(AVHWFram
             if (!s->surfaces_internal)
                 return AVERROR(ENOMEM);
             for (i = 0; i < src_hwctx->nb_surfaces; i++) {
-                qsv_init_surface(dst_ctx, &s->surfaces_internal[i]);
+                ret = qsv_init_surface(dst_ctx, &s->surfaces_internal[i]);
+                if (ret < 0) {
+                    av_freep(&s->surfaces_internal);
+                    return ret;
+                }
                 s->handle_pairs_internal[i].first = (mfxMemId)src_hwctx->surfaces[i];
                 s->handle_pairs_internal[i].second = (mfxMemId)MFX_INFINITE;
                 s->surfaces_internal[i].Data.MemId = (mfxMemId)&s->handle_pairs_internal[i];
             }
+            ret = qsv_init_surface(dst_ctx, &dst_hwctx->reserve_surface);
+            if (ret < 0) {
+                av_freep(&s->surfaces_internal);
+                return ret;
+            }
             dst_hwctx->nb_surfaces = src_hwctx->nb_surfaces;
             if (src_hwctx->surface_type == DXVA2_VideoProcessorRenderTarget)
                 dst_hwctx->frame_type = MFX_MEMTYPE_VIDEO_MEMORY_PROCESSOR_TARGET;
Index: jellyfin-ffmpeg/libavutil/hwcontext_qsv.h
===================================================================
--- libavutil/hwcontext_qsv.h
+++ libavutil/hwcontext_qsv.h
@@ -54,6 +54,12 @@ typedef struct AVQSVFramesContext {
     mfxFrameSurface1 *surfaces;
     int            nb_surfaces;
 
+    /*
+     * This surface store the surface information,
+     * and can be used to init dec, enc and vpp.
+     */
+    mfxFrameSurface1 reserve_surface;
+
     /**
      * A combination of MFX_MEMTYPE_* describing the frame pool.
      */
